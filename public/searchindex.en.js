var relearn_searchindex = [
  {
    "breadcrumb": "Welcome",
    "content": "Welcome to my technical blog and knowledge base!\nTopics üñ• Threathunting Tutorials üñ• OpenBSD Latest posts Threathunting I: Network setup 08.07.2025 Open BSD and Zen 28.06.2025 Threat hunting II: SSH Honeypot setup 13.07.2025 How to monitor systems with monit 08.12.2025 Fixing Yellow Shards in Elasticsearch 12.11.2025 Get in Touch Suggestions or feedback?\nContact me here or visit the project repository.\nYou can also subscribe via RSS.",
    "description": "Latest posts",
    "tags": [],
    "title": "Forensic wheels",
    "uri": "/posts/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Welcome to my technical blog and knowledge base!\nTopics üñ• Threathunting Tutorials üñ• All things OpenBSD Latest posts Threathunting I: Network setup 08.07.2025 Open BSD and Zen 28.06.2025 Threat hunting II: SSH Honeypot setup 13.07.2025 How to monitor systems with monit 08.12.2025 Fixing Yellow Shards in Elasticsearch 12.11.2025 Get in Touch Suggestions or feedback?\nContact me here or visit the project repository.\nYou can also subscribe via RSS.",
    "description": "Latest posts",
    "tags": [],
    "title": "Welcome",
    "uri": "/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Forensic wheels",
    "content": "Introduction Why I Built a Home Lab for Threat Hunting üïµ Network Setup Topology, Hardware and Tools üõ† Firewall configurationüß± Switch configuration What I Learned Whats next Introduction This is a small series I wanted to start, where I write about my small threathunting setup and describe a little what I build and what I am doing with it.\nIn this part, I will describe the Network setup for my Environment, more about how I build the honeypots and the ELK Server I will describe in the follow up articles about threathunting.\nKeep in mind this is for Education and fun, no serious stuff going on here.\nWhy I Built a Home Lab for Threat Hunting üïµ The threat landscape is constantly evolving, with new attack vectors, tools, and tactics appearing almost daily.\nAnd to keep my skills current with real-world threats, I built a home lab dedicated to threat hunting. This environment allows me to safely observe attacks and develop detection and defense methods. I deployed web and shell honeypots, and collect real threat data in a controlled setting.\nIt‚Äôs a practical, hands-on way to explore the behavior of adversaries and its a lot of fun!\nNetwork Setup Topology, Hardware and Tools üõ† For the hardware setup, I kept things lightweight and affordable by using Raspberry Pi devices and open-source tools. The honeypot is based on the well-known Cowrie SSH honeypot and the honeyhttpd HTTP honeypot . It runs on a Raspberry Pi 4 with 8GB of RAM, hosted inside a Docker üê≥ container. On the honeypot host, Filebeat is running to ingest the Cowrie logs into the ELK stack.\nFor the ELK stack, I used a Raspberry Pi 5 with 16GB of RAM, running Debian. The ELK services are also containerized using Docker. The stack is based on the DShield-SIEM project, which I customized to better fit my needs. I‚Äôll dive deeper into those modifications and the ELK setup in a follow-up article.\nThe network topology is straightforward but deliberately segmented. The router is connected to a managed switch, which is responsible for handling VLAN separation. Both the honeypot and the ELK server are connected to this switch and are placed in an isolated VLAN (VLAN210). This VLAN is dedicated exclusively to threat hunting, ensuring that any potentially malicious traffic remains fully contained and cannot interfere with the rest of the home network.\nMy client system üíª is the only machine allowed to connect from outside the VLAN to both the ELK server and the honeypot. This connection is strictly for maintenance and administrative purposes. The ELK server is allowed to access the internet, primarily to pull threat intelligence data from external sources and security feeds.\nIn contrast, the honeypot is completely blocked from internet access, with the exception of SSH and HTTP traffic going in and out of it. These are the only services deliberately exposed to simulate vulnerable endpoints. Communication between the honeypot and the ELK server is allowed for log ingestion and analysis. However, I intend to introduce stricter controls on this internal traffic in the future to further reduce the attack surface.\nFirewall configurationüß± For the pf(1) configuration It was as always with UNIX fairly easy to get to work:\nmatch in quick log on egress proto tcp from any to any port 22 flags S/SA rdr-to $honeypot port 2222 match in quick log on egress proto tcp from any to any port 443 flags S/SA rdr-to $honeypot port 4433 This rule makes sure any incoming TCP connection attempt to port 22 (SSH) and port 443 (HTTPS) is immediately intercepted, logged, and transparently redirected to the $honeypot server listening on port 2222 or 4433 for HTTPS Traffic.\nSwitch configuration Here you can see my managed switch configuration. Port 5 (honeypot) and port 3 (ELK) is assigned to VLAN210, port 2 is the router it needs to talk into both networks and at port 1 is my workstation to access the theathunting environment.\nWhat I Learned Building and maintaining this lightweight honeypot and monitoring setup on Raspberry Pi devices has been an insightful experience. Here are some key takeaways:\nResource Efficiency: Raspberry Pis provide a surprisingly capable platform for running complex services like Cowrie honeypot and the ELK stack in Docker containers, keeping costs and power consumption low.\nNetwork Segmentation Matters: Isolating the honeypot and ELK server in a dedicated VLAN (VLAN210) effectively contains malicious traffic, protecting the rest of the home network from potential threats.\nControlled Access Is Crucial: Restricting external access to only authorized clients and limiting the honeypot‚Äôs internet connectivity reduces the attack surface while still enabling useful data collection.\nLogging and Data Collection: Using Filebeat to ship logs from the honeypot to the ELK stack provides real-time visibility into attacker behavior, which is essential for threat hunting and incident response.\nCustomization Pays Off: Adapting existing tools and SIEM projects (like DShield) to specific needs improves effectiveness and allows for tailored threat detection.\nFuture Improvements: There is always room to tighten internal communication rules and harden the setup further to minimize risk and improve operational security.\nThis project highlights the balance between practical constraints and security needs, demonstrating that even modest hardware can contribute significantly to threat intelligence and network defense.\nI drew inspiration for this setup from the DShield SIEM project by SANS and would like to express my gratitude for their valuable work.\nWhats next Next I had to build the ssh honeypot and the HTTP Honeypot, stay tuned for the follow up!",
    "description": "Introduction Why I Built a Home Lab for Threat Hunting üïµ Network Setup Topology, Hardware and Tools üõ† Firewall configurationüß± Switch configuration What I Learned Whats next Introduction This is a small series I wanted to start, where I write about my small threathunting setup and describe a little what I build and what I am doing with it.",
    "tags": [
      "Threathunting",
      "Honeypot",
      "Visibility"
    ],
    "title": "Threathunting I: Network setup",
    "uri": "/posts/threathuntingnet/index.html"
  },
  {
    "breadcrumb": "Welcome",
    "content": "Hi, I‚Äôm Dirk ‚Äî a security engineer with a deep passion for skateboarding and digital forensics.\nSkateboarding is more than a hobby to me; it‚Äôs a source of creativity, freedom, and community. It shapes how I approach challenges ‚Äî with persistence, balance, and a mindset open to innovation.\nBeyond that, I‚Äôm an OpenBSD enthusiast. I‚Äôve built an OpenBSD-based router and threat-hunting infrastructure to stay ahead in cybersecurity. I appreciate OpenBSD for its simplicity, security, and elegance ‚Äî qualities I strive to bring to my work.\nI‚Äôm also a longtime Emacs user, relying on it daily for coding, writing, and organizing my thoughts. It‚Äôs part of how I stay productive and focused.\nIn cybersecurity, I‚Äôm committed to continuous growth and adapting to new challenges. When I‚Äôm not working on security projects, you‚Äôll find me skating or exploring new ideas inspired by Zen philosophy.\nYou can download my CV as a signed and encrypted PDF for authenticity and privacy. If you need the password to decrypt it, please send me an E-mail\nStay tuned for updates on my journey as a security engineer, skateboarder, and lifelong learner.\nKey ID: `0xC2920C559CAD6CB` Fingerprint: `40CA 727E 96D3 CC2D 8CBB 1540 0C29 20C5 59CA D6CB` SHA-256 Hash: `c7359e0e8bd69ed7cee3ea97453c10e327bfe2416822f54c6390efe72b0d6e7a` publickey",
    "description": "Short intro about myself",
    "tags": [
      "Forensicwheels",
      "Personal"
    ],
    "title": "about",
    "uri": "/about/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Forensic wheels",
    "content": "About As someone who is passionate about security and has an interest in Unix operating systems, OpenBSD particularly captivates due to its dedication to security, stability, and simplicity. In comparison to other OSes, what sets OpenBSD apart? And how do these principles align with my journey through Zen meditation?\nAt first glance, OpenBSD and Zen may appear to be vastly disparate concepts - one being a potent operating system, while the other is a spiritual practice originating from ancient China. However, as I delved deeper into both realms, I uncovered some fascinating similarities.\nSimplicity and Clarity In Zen, simplicity is key to achieving inner clarity and balance. By stripping away unnecessary complexity, OpenBSD aims to create a stable and secure foundation for users. Similarly, in meditation, simplicity helps to quiet the mind and focus on the present moment. This alignment between OpenBSD‚Äôs philosophy and Zen practices extends to their shared emphasis on mindfulness and deliberate decision-making, fostering an environment of security and tranquility in both realms.\nAttention to Detail Both OpenBSD and Zen underscore the significance of attending to detail. In software development, this entails meticulously crafting each line of code to guarantee stability and security. In Zen practice, it involves paying close attention to one‚Äôs breath, posture, and mental state to attain a state of mindfulness. By zeroing in on these details, both OpenBSD and Zen strive for perfection.\nThe Power of Consistency OpenBSD‚Äôs dedication to consistency is manifested in its codebase, where each code change undergoes a thorough code review process. Consistency holds equal importance in Zen practice, as it fosters a sense of routine and stability. By cultivating a consistent daily meditation practice, I have discovered that consistency is instrumental in making progress on my spiritual journey. OpenBSD‚Äôs emphasis on consistency mirrors the principles of Zen, emphasizing the value of diligence and discipline in both domains.\nThe Beauty of Imperfection Finally, both OpenBSD and Zen acknowledge the elegance in imperfection. In software development, imperfections can often be rectified or lessened through meticulous design and testing. In Zen practice, imperfections are perceived as avenues for growth and self-awareness.\nBy acknowledging our imperfections, we can nurture humility and compassion. As I progress in my journey with OpenBSD and Zen, I am consistently struck by the ways in which these two seemingly unrelated realms intersect. By embracing simplicity, attention to detail, consistency, and the beauty of imperfection, both OpenBSD and Zen provide unique perspectives on the nature of software development and personal growth. Stay tuned for further insights from my exploration in the realm of security!",
    "description": "About As someone who is passionate about security and has an interest in Unix operating systems, OpenBSD particularly captivates due to its dedication to security, stability, and simplicity. In comparison to other OSes, what sets OpenBSD apart? And how do these principles align with my journey through Zen meditation?\nAt first glance, OpenBSD and Zen may appear to be vastly disparate concepts - one being a potent operating system, while the other is a spiritual practice originating from ancient China. However, as I delved deeper into both realms, I uncovered some fascinating similarities.",
    "tags": [
      "Forensicwheels",
      "Openbsd",
      "Zen"
    ],
    "title": "Open BSD and Zen",
    "uri": "/posts/openbsdzen/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Forensic wheels",
    "content": "Introduction What is Cowrie? Why Podman over Docker? Preconditions / System setup Ubuntu Installed on Raspberry Pi 4+ System Fully Updated Podman installed and working VLAN Tagging Configured on Network Interface Setup environment, install cowrie as container and adjust configuration üêß Create a Dedicated User for Cowrie (No Login Shell) üê≥ Pull and Configure Cowrie with Podman üõ† cowrie.cfg ‚Äì Basic Overview üöÄ Run Cowrie Container as ‚Äòcowrie‚Äô User üéØ Operating the Honeypot üîÑ Automatically Restart Cowrie Podman Container with systemd üîí Security Notes Log Forwarding with Filebeat üì¶ Install Filebeat on Ubuntu ‚öô Configure and test Filebeat üöÄ Start and Enable Filebeat üéØ TL;DR ‚Äì What Did We Just Do? Whats next Introduction This post provides a brief walkthrough of how to deploy a lightweight, containerized SSH honeypot using Cowrie and Podman, with the goal of capturing and analyzing malicious activity as part of my threat hunting strategy.\nWhat is Cowrie? Cowrie is an interactive SSH and Telnet honeypot designed to emulate a real system, capturing attacker behavior in a controlled environment. It allows defenders and researchers to observe malicious activity without exposing actual infrastructure.\nKey capabilities of Cowrie include\nFull session logging: Records all commands entered by the attacker, along with input/output streams and timing data. Sessions can be saved as plaintext or in formats suitable for replay.\nFake file system and shell environment: Emulates a basic Linux shell with a user-modifiable file system. Attackers can navigate directories, read/write fake files, or attempt to download/upload payloads.\nCommand emulation: Supports a large set of common Unix commands (`ls`, `cat`, `wget`, etc.), allowing attackers to interact naturally, as if on a real system. And can be extended with more commands\nCredential logging: Captures usernames and passwords used in brute-force login attempts or interactive logins.\nFile download capture: Logs and optionally stores any files attackers attempt to retrieve via `wget`, `curl`, or similar tools.\nJSON-formatted logging and integration‚Äôs: Outputs structured logs that are easy to parse and ingest into systems like ELK, Splunk, or custom analysis pipelines.\nCowrie is widely used in research, threat intelligence, and proactive defense efforts to gather Indicators of Compromise (IOCs) and understand attacker tactics,techniques, and procedures (TTPs).\nWhy Podman over Docker? Podman offers several advantages over Docker, particularly in terms of security and system integration. It supports rootless containers, allowing users to run containers without elevated privileges, which reduces the attack surface.\nPodman is daemon-less, integrating more seamlessly with systemd and existing Linux workflows. Additionally, Podman is fully compatible with the Open Container Initiative (OCI) standards, ensuring interoperability and flexibility across container ecosystems.\nPreconditions / System setup Before I proceed with the cowrie setup, I made sure the following preconditions are met:\nUbuntu Installed on Raspberry Pi 4+ I am using a Raspberry Pi 4+ running Ubuntu\nSystem Fully Updated After installation, I made sure system is up to date:\nsudo apt update \u0026\u0026 sudo apt upgrade -y Podman installed and working # Ubuntu 20.10 and newer sudo apt-get -y install podman Run the Hello World Container.In this moment I did not had the cowrie user yet setup so I used my system user to test\npodman run hello-world Trying to pull docker.io/library/hello-world:latest... ... Hello from Docker! This message shows that your installation appears to be working correctly. tho sometimes the pulling fails like that then I had to put `docker.io` in front of the container name like:\npodman run docker.io/hello-world then it would work for sure.\nVLAN Tagging Configured on Network Interface In my network setup for threathunting the honeypot requires VLAN tagging to configured to reachable from the outside, VLAN210 is my restricted Network. Therefore i needed to configure the vlan using nmcli so it‚Äôs persistent across reboots.\nExample: Create a VLAN interface (e.g., VLAN ID 210 on main if) sudo nmcli con add type vlan con-name vlan210 dev mainif id 210 ip4 192.168.210.3/24 gw4 192.168.210.1 sudo nmcli con up vlan210 con-name vlan210: Name of the new VLAN connection. dev mainif: Physical interface to tag. id 210: VLAN ID. ip4, gw4: Optional IP and gateway assignment. This will persist the configuration and activate the VLAN interface immediately. Next I moved on to Install the honeypot.\nSetup environment, install cowrie as container and adjust configuration üêß Create a Dedicated User for Cowrie (No Login Shell) Running the Podman container under a dedicated system user with no login shell is a recommended security best practice. Reasons include:\nPrivilege Separation: Isolates the container from other system processes and users, limiting the potential impact of a compromise.\nReduced Attack Surface: The user has no login shell (e.g., /usr/sbin/nologin), meaning it can‚Äôt be used to log into the system interactively.\nAuditing \u0026 Logging: Helps distinguish container activity in system logs and process lists, making monitoring easier.\nLeast Privilege Principle: The user has only the permissions necessary to run the container ‚Äî nothing more.\n1. Create the ‚Äòcowrie‚Äô user (no home directory, no login shell)\nsudo useradd --system --no-create-home --shell /usr/sbin/nologin cowrie 2. Create necessary directories and set ownership\nsudo mkdir -p /opt/cowrie/etc sudo mkdir -p /opt/cowrie/var sudo mkdir -p /opt/cowrie/var/log/cowrie sudo chown -R cowrie:cowrie /opt/cowrie üê≥ Pull and Configure Cowrie with Podman 3. As the cowrie user, pull the container image\nsudo -u cowrie podman pull docker.io/cowrie/cowrie 4. Copy default config file into persistent volume\nsudo -u cowrie podman run --rm localhost/cowrie_honeypot:latest \\ cat /cowrie/cowrie-git/etc/cowrie.cfg.dist \u003e /opt/cowrie/etc/cowrie.cfg üõ† cowrie.cfg ‚Äì Basic Overview The `cowrie.cfg` file is the main configuration for Cowrie, the SSH/Telnet honeypot we use. It uses INI-style syntax and is divided into sections. Each section begins with a header like [section_name].\nüìÅ Key Sections \u0026 Settings\n[ssh]\nEnable or disable SSH/Telnet and set the port to listen on:: enabled = true listen_port = 2222 [honeypot]\nSet honeypot host name and logpath properties:\nhostname = cowrie-host # Directory where to save log files in. log_path = var/log/cowrie Define login behavior:\nauth_class = AuthRandom auth_class_parameters = 1, 5, 10 I use AuthRandom here which causes to allow access after ‚Äúrandint(2,5)‚Äù attempts. This means the threat actor will fail with some logins and some will be logged in immediately.\n[output_jsonlog]\nConfigure logging and output plugins: [output_jsonlog] enabled = true logfile = ${honeypot:log_path}/cowrie.json epoch_timestamp = false This sets the default log location in the file-system, this is important so that file beat later can pickup on the juicy honeypot log files. This is the whole configuration needed to run the honeypot.\nüìå Notes\nRestart Cowrie after configuration changes. The configuration can be split across multiple `.cfg` files in `cowrie.cfg.d/` for modular setup. üöÄ Run Cowrie Container as ‚Äòcowrie‚Äô User Once I had created the dedicated system user (see earlier section), I was able to run the Cowrie container with Podman using sudo -u and UID mapping.\nStep-by-Step Command explanation sudo -u cowrie podman run -d --name cowrie \\ --uidmap 0:999:1001 \\ -v /opt/cowrie/etc:/cowrie/cowrie-git/etc:Z \\ -v /opt/cowrie/var:/cowrie/cowrie-git/var:Z \\ -p 2222:2222 \\ cowrie/cowrie Explanation sudo -u cowrie: Runs the Podman command as the unprivileged cowrie user. --uidmap 0:999:1001: Maps root (UID 0) inside the container to the cowrie UID on the host. -v /opt/cowrie/etc and /opt/cowrie/var: Mounts configuration and data volumes from the host with `:Z` to apply correct SELinux labels (optional on systems without SELinux). -p 2222:2222: Forwards port 2222 from host to container (Cowrie‚Äôs SSH honeypot port). cowrie/cowrie: The container image name (use latest or specific tag as needed). Benefits: Container runs as non-root on the host: Even if a process inside the container thinks it‚Äôs root, it‚Äôs actually limited to the unprivileged cowrie user outside the container.\nEnhanced security: If the container is compromised, the attacker only gets access as the cowrie user ‚Äî not real root.\nAvoids root-equivalent risks: Prevents privilege escalation or access to sensitive host files and devices.\nüéØ Operating the Honeypot View logs I think to know how to debug the container is important so we start first with the logs:\nsudo -u cowrie podman logs -f cowrie ...snip... [HoneyPotSSHTransport,14,10.0.2.100] Closing TTY Log: var/lib/cowrie/tty/e52d9c508c502347344d8c07ad91cbd6068afc75ff6292f062a09ca381c89e71 after 0.8 seconds [cowrie.ssh.connection.CowrieSSHConnection#info] sending close 0 [cowrie.ssh.session.HoneyPotSSHSession#info] remote close [HoneyPotSSHTransport,14,10.0.2.100] Got remote error, code 11 reason: b'disconnected by user' [HoneyPotSSHTransport,14,10.0.2.100] avatar root logging out [cowrie.ssh.transport.HoneyPotSSHTransport#info] connection lost [HoneyPotSSHTransport,14,10.0.2.100] Connection lost after 2.8 seconds ...snip... Restart container If things go left just restart that thing:\nsudo -u cowrie podman restart cowrie In the logs you can see that cowrie is running and accepting SSH connections:\n...snip... [-] CowrieSSHFactory starting on 2222 [cowrie.ssh.factory.CowrieSSHFactory#info] Starting factory \u003ccowrie.ssh.factory.CowrieSSHFactory object at 0x7fb66f26d0\u003e [-] Ready to accept SSH connections ...snip... When the log says ‚ÄúReady to accept SSH connections‚Äù I tested if I could login:\nssh 192.168.210.3 -p 2222 -l root root@192.168.210.3 password: The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. root@svr04:~# uname -a Linux svr04 3.2.0-4-amd64 #1 SMP Debian 3.2.68-1+deb7u1 x86_64 GNU/Linux root@svr04:~# Stop container Nothing special here:\nsudo -u cowrie podman stop cowrie üîÑ Automatically Restart Cowrie Podman Container with systemd To keep your Cowrie container running reliably and restart it if it stops, use a systemd service with restart policies. Please make sure to double check this part on your side as I am no systemd expert at all, for me this just worked.\nStep 1: Generate a systemd Service File Create `/etc/systemd/system/cowrie-container.service` with the following content: You can create the systemd file with the command:\nsudo -u cowrie podman generate systemd --name cowrie --files --restart-policy=on-failure The resulting file looks somewhat like this\n# container-cowrie.service # autogenerated by Podman 4.3.1 # Fri Sep 19 10:27:47 CEST 2025 [Unit] Description=Podman container-cowrie.service Documentation=man:podman-generate-systemd(1) Wants=network-online.target After=network-online.target RequiresMountsFor=/run/user/1001/containers [Service] User=cowrie Group=cowrie Restart=on-failure Environment=PODMAN_SYSTEMD_UNIT=%n Restart=on-failure TimeoutStopSec=70 ExecStart=/usr/bin/podman start -a cowrie ExecStop=/usr/bin/podman stop -t 10 cowrie ExecStopPost=/usr/bin/podman stop -t 10 cowrie Type=forking [Install] WantedBy=default.target The `‚Äìrestart-policy=on-failure` makes systemd restart the container if it exits with a failure. Step 2: Enable the Service sudo systemctl daemon-reload sudo systemctl enable --now cowrie-container.service Step 3: (Optional) Add a Health Check Script To detect if Cowrie stops accepting connections even if the container is still running, create a health check script running as cowrie:\nCreate `/usr/local/bin/check_cowrie.sh`:\n#!/bin/bash if ! nc -z localhost 2222; then echo \"Cowrie not responding, restarting container\" /usr/bin/podman restart cowrie /usr/local/bin/pushover.sh \"Cowrie was restarted!\" fi This restarts the service and sends out a notification via pushover.\nMake it executable:\nsudo chmod +x /usr/local/bin/check_cowrie.sh sudo chown cowrie:cowrie /usr/local/bin/check_cowrie.sh Create systemd service `/etc/systemd/system/check_cowrie.service`:\n[Unit] Description=Check Cowrie honeypot health [Service] User=cowrie Group=cowrie Type=oneshot ExecStart=/usr/local/bin/check_cowrie.sh Create systemd timer `/etc/systemd/system/check_cowrie.timer`:\n[Unit] Description=Run Cowrie health check every minute [Timer] OnBootSec=1min OnUnitActiveSec=1min Unit=check_cowrie.service [Install] WantedBy=timers.target Enable and start the timer:\nsudo systemctl daemon-reload sudo systemctl enable --now check_cowrie.timer Summary Used Podman‚Äôs systemd integration for automatic restart on container failure. Added a health check timer to detect if Cowrie stops accepting connections and restart proactively. üîí Security Notes The `cowrie` user has no login shell (`/usr/sbin/no login`)\nRunning Cowrie isolated via Podman increases containment\nAll files are owned by `cowrie`, no root access required for normal operation\nLog Forwarding with Filebeat üì¶ Install Filebeat on Ubuntu 1. Add Elastic‚Äôs GPG key and repository\ncurl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elastic.gpg echo \"deb [signed-by=/usr/share/keyrings/elastic.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main\" | \\ sudo tee /etc/apt/sources.list.d/elastic-8.x.list 2. Update APT and install Filebeat\nsudo apt install filebeat ‚öô Configure and test Filebeat 3. Edit Filebeat config\nsudo mg /etc/filebeat/filebeat.yml The filebeat config is straight forward. You have to write a filebeat.input block which contains the path where the logfiles are you need to ingest. And at the end the log-destination (logstash) so that filebeat knows where to send the logs to:\nfilebeat.inputs: - type: log enabled: true paths: - /opt/cowrie/var/log/cowrie/cowrie.json json.keys_under_root: true json.add_error_key: true fields: source: cowrie fields_under_root: true output.logstash: hosts: [\"192.168.123.5:5044\"] 4. (Optional) Test Filebeat config\nsudo filebeat test config logstash: 192.168.210.5:5044... connection... parse host... OK dns lookup... OK addresses: 192.168.210.5 dial up... OK TLS... WARN secure connection disabled talk to server... OK üöÄ Start and Enable Filebeat 5. Enable and start Filebeat\nsudo systemctl enable filebeat sudo systemctl daemon-reload sudo systemctl start filebeat 6. Check Filebeat status and logs\nsudo systemctl status filebeat sudo journalctl -u filebeat -f üéØ TL;DR ‚Äì What Did We Just Do? 1. We deployed Cowrie like pros.\nRan it safely in a Podman container under a non-login user. No mess, no root, no regrets. 2. Logs? Sorted.\nFilebeat scooped up Cowrie‚Äôs logs and shipped them to Elasticsearch. Now we can actually see who‚Äôs knocking on the honeypot door. 3. Everything‚Äôs persistent.\nConfigs and logs live outside the container. Cowrie forgets nothing‚Äîeven after a reboot. 4. Setup is clean and modular.\nEach part (Cowrie, Filebeat, Elasticsearch) does its job. Break one, fix one‚Äîno domino disasters. 5. It‚Äôs nerdy, useful, and kinda fun.\nNow I built a mini threat intel system. Now I can sit back, sip coffee, and watch the kiddies play. Whats next Next I build the HTTP Honeypot",
    "description": "Introduction What is Cowrie? Why Podman over Docker? Preconditions / System setup Ubuntu Installed on Raspberry Pi 4+ System Fully Updated Podman installed and working VLAN Tagging Configured on Network Interface Setup environment, install cowrie as container and adjust configuration üêß Create a Dedicated User for Cowrie (No Login Shell) üê≥ Pull and Configure Cowrie with Podman üõ† cowrie.cfg ‚Äì Basic Overview üöÄ Run Cowrie Container as ‚Äòcowrie‚Äô User üéØ Operating the Honeypot üîÑ Automatically Restart Cowrie Podman Container with systemd üîí Security Notes Log Forwarding with Filebeat üì¶ Install Filebeat on Ubuntu ‚öô Configure and test Filebeat üöÄ Start and Enable Filebeat üéØ TL;DR ‚Äì What Did We Just Do? Whats next Introduction This post provides a brief walkthrough of how to deploy a lightweight, containerized SSH honeypot using Cowrie and Podman, with the goal of capturing and analyzing malicious activity as part of my threat hunting strategy.",
    "tags": [
      "Threathunting",
      "Honeypot"
    ],
    "title": "Threat hunting II: SSH Honeypot setup",
    "uri": "/posts/theathuntinghoneypot/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Forensic wheels",
    "content": "Introduction Requirements Installing Monit on OpenBSD Monit ‚Äì Essential System and Router Services System monitoring runs every 45 seconds. The first check is delayed by 120 seconds to avoid overloading the system immediately after boot.\nset daemon 45 with start delay 120 Monit logs to syslog. `idfile` and `statefile` store Monit‚Äôs persistent state and identity across restarts.\nset log syslog set idfile /var/monit/id set statefile /var/monit/state Limits control buffer sizes and timeouts for program outputs, network I/O, and service start/stop/restart operations. This prevents Monit from hanging or processing excessive data.\nset limits { programOutput: 512 B, sendExpectBuffer: 256 B, fileContentBuffer: 512 B, httpContentBuffer: 1 MB, networkTimeout: 5 seconds programTimeout: 300 seconds stopTimeout: 30 seconds startTimeout: 30 seconds restartTimeout: 30 seconds } Monit will send alerts via local email. Events are queued under `/var/monit/events` to prevent message loss during temporary network problems.\nset mailserver localhost set eventqueue basedir /var/monit/events slots 200 set mail-format { from: root@monit } set alert root@localhost not on { instance, action } Simply comment out or delete all `set alert` entries:\n# set alert root@localhost not on { instance, action } After this, Monit will not send any emails, but it will still monitor services.\nMonit HTTP interface is on port 2812. Access is restricted to localhost, a local subnet (`192.168.X.0/24`), and an admin user with a password.\nset httpd port 2812 and allow localhost allow 192.168.X.0/255.255.255.0 allow admin:foobar Monit will start all monitored services automatically on reboot.\nset onreboot start This monitors overall system health:\n1- and 5-minute load per CPU core CPU usage Memory and swap usage If thresholds are exceeded, it triggers `pushover.sh` for alerts.\ncheck system $HOST if loadavg (1min) per core \u003e 2 for 5 cycles then exec /usr/local/bin/pushover.sh if loadavg (5min) per core \u003e 1.5 for 10 cycles then exec /usr/local/bin/pushover.sh if cpu usage \u003e 95% for 10 cycles then exec /usr/local/bin/pushover.sh if memory usage \u003e 75% then exec /usr/local/bin/pushover.sh if swap usage \u003e 25% then exec /usr/local/bin/pushover.sh group system `/home` filesystem is monitored for:\nDisk space and inode usage Read/write throughput (MB/s and IOPS) Service response time Alerts are sent via `pushover.sh` if any threshold is exceeded.\ncheck filesystem home_fs with path /dev/sd0k start program = \"/sbin/mount /home\" stop program = \"/sbin/umount /home\" if space usage \u003e 90% then exec /usr/local/bin/pushover.sh if inode usage \u003e 95% then exec /usr/local/bin/pushover.sh if read rate \u003e 8 MB/s for 20 cycles then exec /usr/local/bin/pushover.sh if read rate \u003e 800 operations/s for 15 cycles then exec /usr/local/bin/pushover.sh if write rate \u003e 8 MB/s for 20 cycles then exec /usr/local/bin/pushover.sh if write rate \u003e 800 operations/s for 15 cycles then exec /usr/local/bin/pushover.sh if service time \u003e 10 milliseconds for 3 times within 15 cycles then exec /usr/local/bin/pushover.sh group system Root filesystem `/` has similar checks but shorter cycles since it‚Äôs critical to system stability.\ncheck filesystem root_fs with path /dev/sd0a start program = \"/sbin/mount /\" stop program = \"/sbin/umount /\" if space usage \u003e 90% then exec /usr/local/bin/pushover.sh if inode usage \u003e 95% then exec /usr/local/bin/pushover.sh if read rate \u003e 8 MB/s for 5 cycles then exec /usr/local/bin/pushover.sh if read rate \u003e 800 operations/s for 5 cycles then exec /usr/local/bin/pushover.sh if write rate \u003e 8 MB/s for 5 cycles then exec /usr/local/bin/pushover.sh if write rate \u003e 800 operations/s for 5 cycles then exec /usr/local/bin/pushover.sh if service time \u003e 10 milliseconds for 3 times within 5 cycles then exec /usr/local/bin/pushover.sh group system Monit ensures secure permissions for `/root`. If permissions are wrong, monitoring for this directory is disabled to avoid false alarms.\ncheck directory bin with path /root if failed permission 700 then unmonitor if failed uid 0 then unmonitor if failed gid 0 then unmonitor group system A network host is ping-checked. Frequent failures trigger alerts. Dependencies on interfaces and services ensure checks only run when the network is up.\ncheck host homeassistant with address 192.168.X.19 if failed ping then alert if 5 restarts within 10 cycles then exec /usr/local/bin/pushover.sh group network depends on iface_in,dhcpd,unbound Monit watches network interface `pppoeX`:\nRestarts interface if link goes down Alerts on saturation or high upload Limits repeated restarts to avoid loops check network iface_out with interface pppoeX start program = \"/bin/sh /etc/netstart pppoeX\" if link down then restart else exec /usr/local/bin/pushover.sh if changed link then exec /usr/local/bin/pushover.sh if saturation \u003e 90% then exec /usr/local/bin/pushover.sh if total uploaded \u003e 5 GB in last hour then exec /usr/local/bin/pushover.sh if 5 restarts within 10 cycles then exec /usr/local/bin/pushover.sh group network DNS resolver `unbound` is monitored by PID and port. Failures trigger a restart, repeated failures trigger alerts.\ncheck process unbound with pidfile /var/unbound/unbound.pid start program = \"/usr/sbin/rcctl start unbound\" stop program = \"/usr/sbin/rcctl stop unbound\" if failed port 53 for 3 cycles then restart if 3 restarts within 10 cycles then exec /usr/local/bin/pushover.sh group network depends on dnscrypt_proxy,iface_out,iface_in DHCP server is monitored. Missing process triggers a restart. Alerts are sent if failures happen repeatedly.\ncheck process dhcpd with matching /usr/sbin/dhcpd start program = \"/usr/sbin/rcctl start dhcpd\" stop program = \"/usr/sbin/rcctl stop dhcpd\" if does not exist then restart if 2 restarts within 10 cycles then exec /usr/local/bin/pushover.sh group network depends on iface_in NTP daemon ensures time synchronization. Missing process triggers restart; repeated issues generate alerts.\ncheck process ntpd with matching /usr/sbin/ntpd start program = \"/usr/sbin/rcctl start ntpd\" stop program = \"/usr/sbin/rcctl stop ntpd\" if does not exist then restart if 5 restarts within 5 cycles then exec /usr/local/bin/pushover.sh group network depends on iface_out vnStat daemon monitors network traffic statistics. Monit restarts it if it stops and alerts on repeated failures.\ncheck process vnstatd with matching /usr/local/sbin/vnstatd start program = \"/usr/sbin/rcctl start vnstatd\" stop program = \"/usr/sbin/rcctl stop vnstatd\" if does not exist then restart if 5 restarts within 15 cycles then exec /usr/local/bin/pushover.sh group network depends on iface_out Adding Pushover Alerts Testing and Maintenance Conclusion Using Monit together with Pushover is an excellent way to keep a close eye on an OpenBSD router. Monit is tiny, fast, and reliable ‚Äî perfect for embedded hardware. Pushover provides instant alerts with almost no configuration or overhead.\nFor a home router or small business network, this combination gives you semi professional-grade monitoring with minimal effort.",
    "description": "Introduction Requirements Installing Monit on OpenBSD Monit ‚Äì Essential System and Router Services System monitoring runs every 45 seconds. The first check is delayed by 120 seconds to avoid overloading the system immediately after boot.\nset daemon 45 with start delay 120 Monit logs to syslog. `idfile` and `statefile` store Monit‚Äôs persistent state and identity across restarts.\nset log syslog set idfile /var/monit/id set statefile /var/monit/state Limits control buffer sizes and timeouts for program outputs, network I/O, and service start/stop/restart operations. This prevents Monit from hanging or processing excessive data.",
    "tags": [
      "Forensicwheels",
      "Openbsd",
      "Personal",
      "Visibility"
    ],
    "title": "How to monitor systems with monit",
    "uri": "/posts/monitmon/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Forensic wheels",
    "content": "Introduction If you‚Äôre running Elasticsearch on a single node ‚Äî like a Raspberry Pi or small lab setup like I am ‚Äî you might notice some indices appear with a yellow health status.\nThis show article explains what that means and how to fix it, especially in resource-constrained, single-node environments.\nWhat Does ‚ÄúYellow‚Äù Mean? In Elasticsearch:\ngreen: All primary and replica shards are assigned and active. yellow: All primary shards are active, but at least one replica shard is unassigned. red: At least one primary shard is missing ‚Üí critical! Why Yellow Happens on Single Nodes In single-node clusters, Elasticsearch cannot assign replica shards (because replicas must be on a different node). So any index with replicas will always be yellow unless:\nYou add more nodes (not ideal on a Raspberry Pi) Or: You disable replicas (number_of_replicas: 0) Step-by-Step: Diagnose Yellow Shards 1. List all yellow indices GET _cat/indices?v\u0026health=yellow 2. See why a shard is unassigned GET _cluster/allocation/explain 3. Inspect shard assignment of a specific index GET _cat/shards/.monitoring-beats-7-2025.08.06?v Example output:\nindex shard prirep state docs store ip node .monitoring-beats-7-2025.08.06 0 p STARTED 7790 5.9mb 127.0.0.1 mynode .monitoring-beats-7-2025.08.06 0 r UNASSIGNED ‚Üí The r (replica) is unassigned ‚Üí yellow status.\nHow to Fix It A. Fix an individual index Set replicas to zero:\nPUT .monitoring-beats-7-2025.08.06/_settings { \"index\" : { \"number_of_replicas\" : 0 } } This changes the index health from yellow to green.\nB. Automatically fix all yellow indices If you want to automate the fix, use this (Kibana Dev Tools):\nGET _cat/indices?health=yellow\u0026format=json Then for each index in the result:\nPOST \u003cyour_index\u003e/_settings { \"index\": { \"number_of_replicas\": 0 } } C. Prevent future yellow indices Disable replicas by default using an index template:\nPUT _template/no-replica-default { \"index_patterns\": [\"*\"], \"settings\": { \"number_of_replicas\": 0 } } \u003e ‚ö†Ô∏è This applies to all future indices. Only do this in single-node environments.\nConclusion Yellow indices aren‚Äôt dangerous by default ‚Äî they just mean you‚Äôre missing redundancy. In small environments, it‚Äôs perfectly safe to run with zero replicas.\nJust don‚Äôt forget to:\nMonitor your shard health Disable replicas if you only have one node Automate where you can",
    "description": "Introduction If you‚Äôre running Elasticsearch on a single node ‚Äî like a Raspberry Pi or small lab setup like I am ‚Äî you might notice some indices appear with a yellow health status.\nThis show article explains what that means and how to fix it, especially in resource-constrained, single-node environments.\nWhat Does ‚ÄúYellow‚Äù Mean? In Elasticsearch:\ngreen: All primary and replica shards are assigned and active. yellow: All primary shards are active, but at least one replica shard is unassigned. red: At least one primary shard is missing ‚Üí critical! Why Yellow Happens on Single Nodes In single-node clusters, Elasticsearch cannot assign replica shards (because replicas must be on a different node). So any index with replicas will always be yellow unless:",
    "tags": [
      "Forensicwheels"
    ],
    "title": "Fixing Yellow Shards in Elasticsearch",
    "uri": "/posts/yellowshardsinelastic/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Forensic wheels",
    "content": "Why GPG? In an age where digital identities are easily faked and impersonation is just a few clicks away, I decided to take a step forward in securing mine. GPG (GNU Privacy Guard) provides a robust way to authenticate, encrypt, and sign digital content. In this post, I‚Äôll walk you through how I:\nCreated a GPG key pair Set up subkeys and stored them on my YubiKey Published my public key on my website Signed and encrypted personal documents for secure public sharing Configured email signing using GPG Step 1: Installing GPG To start, I made sure GPG was installed. Here‚Äôs how I did it on each of my systems:\nOn Ubuntu/Debian:\nsudo apt update \u0026\u0026 sudo apt install gnupg On Fedora 40:\nsudo dnf install gnupg2 On OpenBSD 7.6:\ndoas pkg_add gnupg Check your installation:\ngpg --version Step 2: Creating My GPG Key Pair I created a new key using:\ngpg --full-generate-key Here‚Äôs what I chose:\nKey type: ed25519 (modern and compact) or RSA and RSA (widely compatible) Key length: 4096 bits (if RSA) Expiration: 2 years (I can always renew) My real name or handle My preferred contact email A strong passphrase, saved in a password manager After generating the key, I listed it and saved the fingerprint:\ngpg --list-keys --fingerprint gpg: \"Trust-DB\" wird √ºberpr√ºft gpg: marginals needed: 3 completes needed: 1 trust model: pgp gpg: Tiefe: 0 g√ºltig: 1 signiert: 0 Vertrauen: 0-, 0q, 0n, 0m, 0f, 1u gpg: n√§chste \"Trust-DB\"-Pflicht√ºberpr√ºfung am 2026-08-04 [keyboxd] --------- pub ed25519 2025-08-04 [SC] [verf√§llt: 2026-08-04] A371 9309 4ED4 B0E6 AD2E 5022 D7D6 4842 8DBD 39FD uid [ ultimativ ] Dirk.L (Dirk.L's official key) \u003cpolymathmonkey@keksmafia.org\u003e Step 3: Creating Subkeys and Moving Them to My YubiKey I created subkeys for:\nSigning Encryption Authentication Then, I moved the subkeys to my YubiKey using GPG‚Äôs interactive editor:\ngpg --edit-key Dirk.L gpg\u003e addkey \u003c- once for signing, engryption, auth gpg\u003e keytocard gpg\u003e save ‚ö†Ô∏è Be cautious: Once moved to the YubiKey, the subkey no longer exists on disk.\nMore guidance: YubiKey + GPG official instructions\nStep 4: Publishing My Public Key I exported my key in ASCII format so others could import it easily:\ngpg --export --armor you@example.com \u003e publickey.asc I uploaded publickey.asc to my website and linked it like this:\n\u003ca href=\"/publickey.asc\"\u003eüîë Download my GPG public key\u003c/a\u003e Additionally, I displayed my key‚Äôs fingerprint on the page so that people can verify its authenticity manually.\nStep 5: Email Signing and Encryption I configured email signing using my GPG key.\nFor Thunderbird (Linux, OpenBSD, Windows):\nOpenPGP support is built-in. I enabled signing for all outgoing mail. The key lives on the YubiKey, so no key is stored on disk. For Mutt / CLI mailers:\nI used `gpg-agent` for passphrase and key handling. Configured .muttrc to sign and/or encrypt automatically. Signing ensures message authenticity. If recipients have my key, they can encrypt replies.\nStep 6: Signing and Encrypting Documents for the Public To safely share personal certificates and private files, I signed and optionally encrypted them:\n# Sign only (adds signature block) gpg --sign --armor diploma.pdf # Sign and encrypt with a password (no public key needed) gpg --symmetric --armor --cipher-algo AES256 diploma.pdf This way, the document is verifiably mine and only decryptable with the shared password.\nThe encrypted .asc files can be uploaded to the website, with instructions for downloading and decrypting.\nStep 7: Offline Backup of My Master Key Before moving entirely to the YubiKey, I backed up the master key offline:\ngpg --export-secret-keys --armor \u003e masterkey-backup.asc I stored it on an encrypted USB drive with either one:\nLUKS (on Linux) OpenBSD softraid(4) encryption Conclusion Rolling out GPG was super easy. With my identity cryptographically verifiable, email signing in place, and secure document sharing live on my site, I now have a strong, decentralized identity system.\nUseful Links GnuPG Official Website FSF‚Äôs Email Self-Defense Guide YubiKey GPG Configuration OpenPGP Public Key Directory",
    "description": "Why GPG? In an age where digital identities are easily faked and impersonation is just a few clicks away, I decided to take a step forward in securing mine. GPG (GNU Privacy Guard) provides a robust way to authenticate, encrypt, and sign digital content. In this post, I‚Äôll walk you through how I:\nCreated a GPG key pair Set up subkeys and stored them on my YubiKey Published my public key on my website Signed and encrypted personal documents for secure public sharing Configured email signing using GPG Step 1: Installing GPG To start, I made sure GPG was installed. Here‚Äôs how I did it on each of my systems:",
    "tags": [
      "Forensicwheels"
    ],
    "title": "Putting my gpg key on my yubikey",
    "uri": "/posts/gpgonmyyubi/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Forensic wheels",
    "content": "Introduction So I had this USB Disk attached to my OpenBSD Router used as storage, one saturday when I was walking by I noticed the weird clicking sounds from the disk. So I knew my time was running before the disc would fail.\nCuriously, when I plugged the same drive into a Linux box, it was detected and even showed a valid OpenBSD partition table. That gave me a glimmer of hope: maybe the hardware wasn‚Äôt completely dead yet.\nSo, for fun (and a little bit of stubborn curiosity), I decided to spend the weekend seeing how much I could rescue from it.\nThis post documents the process part forensic experiment, part recovery attempt, and part ‚Äúlet‚Äôs see what happens if I do this.‚Äù\nPhase 1: Identifying the Disk under Linux Before doing anything risky, I wanted to be sure I was imaging the right disk. The idea was to identify the OpenBSD partition and dump it to an image file.\nListing block devices lsblk -o NAME,SIZE,FSTYPE,TYPE,LABEL,UUID That gives a good overview which disks are present, how large they are, and what filesystems they contain. Sure enough, my external USB drive showed up as /dev/sda.\nInspecting partition table sudo fdisk -l /dev/sda Example output:\nDisk /dev/sda: 931.5 GiB, 1000204883968 bytes, 1953525164 sectors Disk model: External USB 3.0 Sector size: 512 bytes Disklabel type: dos Device Boot Start End Sectors Size Id Type /dev/sda4 * 64 1953525163 1953525100 931.5G a6 OpenBSD Perfect. The OpenBSD partition was still there (/dev/sda4), and it even reported the correct size.\nThe Start sector (64) is important later for offset calculations. Type a6 OpenBSD confirmed the filesystem was OpenBSD-specific (likely softraid). Knowing the sector size (512 bytes) ensured that later tools like dd or ddrescue wouldn‚Äôt misalign reads. At this point, the goal was to make a bit-for-bit copy of that partition, compress it, and work on the image rather than risk further damage to the actual disk.\nPhase 2: Creating a Compressed Disk Image For imaging, I decided to use GNU ddrescue it‚Äôs great for flaky disks and can retry sectors intelligently.\nInstalling ddrescue On Fedora, installation was trivial:\nsudo dnf install ddrescue First Attempt (Quick and Dirty) I tried a fast, one-shot dump not ideal for a failing disk, but I wanted to see if it would work at all:\nsudo ddrescue -d -r3 /dev/sda4 - - | xz -T0 -c \u003e openbsd_sda4.img.xz That command streams data directly from the device, compresses it with xz, and writes the result. It works if the disk is healthy. Mine wasn‚Äôt, so it failed partway through.\nSecond Attempt (Proper Forensic Mode) So I switched to the safer, resumable method:\nsudo ddrescue -d -r3 /dev/sda4 openbsd_sda4.img openbsd_sda4.log xz -T0 openbsd_sda4.img sha256sum openbsd_sda4.img \u003e openbsd_sda4.img.sha256 This time, ddrescue created a detailed log file so I could resume later if the system froze or the disk disconnected. It took most of the night, but eventually I had a clean (or mostly clean) image.\nExplanation of parameters\n-r3 retries each bad block 3 times -d enables direct disk I/O The .log file lets you stop and restart without losing progress xz -T0 uses all CPU cores for compression After the dump, I verified the output:\nls -lh openbsd_sda4.img.xz xz -t openbsd_sda4.img.xz # test integrity sha256sum openbsd_sda4.img.xz \u003e openbsd_sda4.img.xz.sha256 Everything checked out a ~450 GB compressed image file safely sitting on my main system.\nPhase 3: Simulating Disk Damage (For Fun and Testing) Since the real disk was unstable, I wanted a safe way to experiment. So I created a copy of the image and simulated damage to practice recovery techniques.\nCreating the test image sudo dd if=/dev/sda4 of=openbsd_sda4.img bs=4M status=progress Simulating corruption To emulate bad sectors:\ndd if=/dev/zero of=openbsd_sda4.img bs=512 count=10 seek=1000 conv=notrunc Now the image contained 10 intentionally corrupted sectors perfect for testing.\nRecovering from the damaged image ddrescue -d -r3 openbsd_sda4.img openbsd_sda4_recovered.img openbsd_sda4_recovery.log And just like that, I was able to practice recovery without touching the actual hardware again.\nOptional Compression xz -T0 openbsd_sda4.img It‚Äôs amazing how much you can still do with raw disk images and a few tools.\nPhase 4: Performance Tuning and System Stability During the rescue, I learned (the hard way) that ddrescue can saturate I/O and make your system lag like crazy. So I ended up using this combination for a gentler approach:\nsudo ionice -c2 -n7 nice -n19 ddrescue -b 4096 -B 4096 /dev/sda4 openbsd_sda4.img And, for long operations, running it inside tmux:\ntmux new-session -s rescue sudo ddrescue -d -r3 /dev/sda4 openbsd_sda4.img openbsd_sda4.log # Detach with Ctrl-B D Later, I could simply:\ntmux attach -t rescue That setup saved me more than once when I accidentally closed an SSH session.\nPhase 5: Next Steps ‚Äî Future Analysis Once I had a full image, the plan was to:\nDecompress it (unxz openbsd_sda4.img.xz) Attach it as a loopback device under Linux, or use vnconfig under OpenBSD Attempt to reassemble the softraid volume using bioctl If all goes well ‚Äî mount the decrypted filesystem and access my old data That‚Äôs a topic for another weekend. But getting to this point already felt like a small victory.\nConclusion What started as a ‚Äúlet‚Äôs see if I can still read this disk‚Äù experiment turned into a proper mini-forensics exercise. Even though the original USB drive was dying, I managed to preserve most of its data and learned a ton in the process.\nAllover it was quite fun to do something forensics related on a OpenBSD target, I guess it is something you don‚Äôt come across everyday but when you do its good to be prepared I think.\nKey takeaways:\nddrescue is your friend for unstable media Always work on images, not the original device Compression and checksums are cheap insurance And most importantly: never underestimate what you can recover with a bit of patience Not a bad way to spend a weekend. Nevertheless I would like to find a purely OpenBSD Based solution. But I was not able to find the dd_rescue in the ports and packages of OpenBSD. If someone knows how to do this on purely OpenBSD please contact me.\nAppendix Device summary Device: /dev/sda Partition: /dev/sda4 Size: ~931 GiB Partition type: a6 (OpenBSD) Start sector: 64 Sector size: 512 bytes Estimated time and storage Depending on USB speed:\nImaging took about 2‚Äì3 hours Compressed image size: ~40‚Äì60% of original Tools used dd, ddrescue, xz fdisk, lsblk, sha256sum tmux, ionice, dstat, iotop",
    "description": "Introduction So I had this USB Disk attached to my OpenBSD Router used as storage, one saturday when I was walking by I noticed the weird clicking sounds from the disk. So I knew my time was running before the disc would fail.\nCuriously, when I plugged the same drive into a Linux box, it was detected and even showed a valid OpenBSD partition table. That gave me a glimmer of hope: maybe the hardware wasn‚Äôt completely dead yet.",
    "tags": [
      "Forensicwheels",
      "Personal",
      "Openbsd"
    ],
    "title": "Rescue to the softraid",
    "uri": "/posts/rescuetotheraid/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag - Forensicwheels",
    "uri": "/tags/forensicwheels/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag - Openbsd",
    "uri": "/tags/openbsd/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag - Personal",
    "uri": "/tags/personal/index.html"
  },
  {
    "breadcrumb": "Welcome",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag - Visibility",
    "uri": "/tags/visibility/index.html"
  },
  {
    "breadcrumb": "Welcome",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category - Forensic",
    "uri": "/categories/forensic/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag - Honeypot",
    "uri": "/tags/honeypot/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag - Threathunting",
    "uri": "/tags/threathunting/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category - Threathunting",
    "uri": "/categories/threathunting/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category - Personal",
    "uri": "/categories/personal/index.html"
  },
  {
    "breadcrumb": "Welcome¬†\u003e¬†Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag - Zen",
    "uri": "/tags/zen/index.html"
  }
]
