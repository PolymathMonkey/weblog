#+hugo_base_dir: ../
#+hugo_section: ./posts/
#+hugo_weight: auto
#+hugo_auto_set_lastmod: t
#+title: Adventures in threathunting
#+seq_todo: DRAFT TODO DONE
#+FILETAGS: :threathunting:
#+TAGS: @personal @forensic @zen @threathunting
#+TAGS: openbsd honeypot zen personal canarytokens skateboarding visibility

* DONE Threathunting I: Network setup                                                     :@threathunting:honeypot:visibility:
CLOSED: [2025-07-08 Di 09:15]
:PROPERTIES:
:EXPORT_AUTHOR: Dirk
:EXPORT_HUGO_FRONT_MATTER_FORMAT: yaml
:EXPORT_OPTIONS: toc:2
:HUGO_TITLE: Threathunting at home
:EXPORT_FILE_NAME: threathuntingnet
:EXPORT_DATE: 2025-05-26T16:21:00-05:00
:CUSTOM_ID: threathuntingathome
:END:
** Introduction

This is a small series I wanted to start, where I write about my small
threathunting setup and describe a little what I build and what I am doing
with it.

In this part, I will describe the Network setup for my Environment, more about
how I build the honeypots and the ELK Server I will describe in the follow up
articles about threathunting.

Keep in mind this is for Education and fun, no serious stuff going on here.

*** Why I Built a Home Lab for Threat Hunting  üïµ
The threat landscape is constantly evolving, with new attack vectors, tools,
and tactics appearing almost daily.  

And to keep my skills current with real-world threats, I built a home lab dedicated
to threat hunting. This environment allows me to safely observe attacks and
develop detection and defense methods. I deployed web and shell honeypots,
and collect real threat data in a controlled setting.

It‚Äôs a practical, hands-on way to explore the behavior of adversaries and its a
lot of fun!

** Network Setup
*** Topology, Hardware and Tools üõ†

[[../img/mynet.png]]

For the **hardware setup**, I kept things lightweight and affordable by using
Raspberry Pi devices and open-source tools. The honeypot is based on the
well-known [[https://docs.cowrie.org/en/latest/][Cowrie SSH honeypot]] and the [[https://github.com/bocajspear1/honeyhttpd][honeyhttpd HTTP honeypot]] .
It runs on a **Raspberry Pi 4 with 8GB of RAM**, hosted inside a Docker üê≥
container. On the honeypot host, **Filebeat** is running to ingest the Cowrie
logs into the ELK stack. @@comment: Write about honeypot setup @@

For the **ELK stack**, I used a **Raspberry Pi 5 with 16GB of RAM**, running
Debian. The ELK services are also containerized using Docker. The stack is
based on the [[https://github.com/bruneaug/DShield-SIEM][DShield-SIEM]] project, which I customized to better fit
my needs. I‚Äôll dive deeper into those modifications and the ELK setup in
a follow-up article.

The network topology is straightforward but deliberately segmented. The router
is connected to a managed switch, which is responsible for handling VLAN
separation. Both the honeypot and the ELK server are connected to this switch
and are placed in an **isolated VLAN (VLAN210)**. This VLAN is dedicated
exclusively to **threat hunting**, ensuring that any potentially malicious
traffic remains fully contained and cannot interfere with the rest of the
home network.

My client system üíª is the only machine allowed to connect from outside the
VLAN to both the ELK server and the honeypot. This connection is strictly
for maintenance and administrative purposes. The ELK server is allowed to
access the internet, primarily to pull threat intelligence data from
external sources and security feeds.

In contrast, the **honeypot** is completely **blocked from internet access**,
with the exception of **SSH and HTTP traffic** going in and out of it. These
are the only services deliberately exposed to simulate vulnerable endpoints.
Communication between the honeypot and the ELK server is allowed for log
ingestion and analysis. However, I intend to introduce stricter controls on
this internal traffic in the future to further reduce the attack surface.

*** Firewall configurationüß± @@comment: don't forget to add the HTTP pf rule@@
For the pf(1) configuration It was as always with UNIX fairly easy to get to work:
#+begin_src sh
match in quick log on egress proto tcp from any to any port 22 flags S/SA rdr-to $honeypot port 2222
match in quick log on egress proto tcp from any to any port 443 flags S/SA rdr-to $honeypot port 4433 
#+end_src

This rule makes sure any incoming TCP connection attempt to port 22 (SSH) and
port 443 (HTTPS) is immediately intercepted, logged, and transparently
redirected to the $honeypot server listening on port 2222 or 4433 for HTTPS Traffic.@@comment: Link to article with full ruleset@@

*** Switch configuration
@@comment: TBD@@
Here you can see my managed switch configuration. Port 5 (honeypot) is only
assigned to VLAN210 like port 5 too, port 2 is the router it needs to talk
into both networks and at port 1 is my workstation to access the theathunting
environment.

[[../posts/img/switch.png]]


** What I Learned
Building and maintaining this lightweight honeypot and monitoring setup on
Raspberry Pi devices has been an insightful experience. Here are some key takeaways:

- **Resource Efficiency**: Raspberry Pis provide a surprisingly capable
  platform for running complex services like Cowrie honeypot and the ELK stack
  in Docker containers, keeping costs and power consumption low.

- **Network Segmentation Matters**: Isolating the honeypot and ELK server in a
  dedicated VLAN (VLAN210) effectively contains malicious traffic, protecting
  the rest of the home network from potential threats.

- **Controlled Access Is Crucial**: Restricting external access to only
  authorized    clients and limiting the honeypot's internet connectivity
  reduces the attack surface while still enabling useful data collection.

- **Logging and Data Collection**: Using Filebeat to ship logs from the
  honeypot to the ELK stack provides real-time visibility into attacker
  behavior, which is essential for threat hunting and incident response.

- **Customization Pays Off**: Adapting existing tools and SIEM projects
  (like DShield) to specific needs improves effectiveness and allows for
  tailored threat detection.

- **Future Improvements**: There is always room to tighten internal
  communication rules and harden the setup further to minimize risk and
  improve operational security.

This project highlights the balance between practical constraints and security
needs, demonstrating that even modest hardware can contribute significantly
to threat intelligence and network defense.

I drew inspiration for this setup from the DShield SIEM project by SANS and
would like to express my gratitude for their valuable work.

** Whats next
Next I had to build the ssh honeypot and the HTTP Honeypot, stay tuned for the
follow up!


* DONE Threat hunting II: SSH Honeypot setup                                              :@threathunting:honeypot:
CLOSED: [2025-07-13 So 07:38]
:PROPERTIES:
:EXPORT_AUTHOR: Dirk
:EXPORT_HUGO_FRONT_MATTER_FORMAT: yaml
:EXPORT_OPTIONS: toc:2
:HUGO_TITLE: Threathunting at home
:EXPORT_FILE_NAME: theathuntinghoneypot
:EXPORT_DATE: 2025-05-26T16:21:00-05:00
:CUSTOM_ID: theathuntingathome
:END:
** Introduction
This post provides a brief walkthrough of how to deploy a lightweight,
containerized SSH honeypot using Cowrie and Podman, with the goal of
capturing and analyzing malicious activity as part of my threat hunting
strategy.

** What is Cowrie?
Cowrie is an interactive SSH and Telnet honeypot designed to emulate a
real system, capturing attacker behavior in a controlled environment.
It allows defenders and researchers to observe malicious activity without
exposing actual infrastructure.

_Key capabilities of Cowrie include_

- *Full session logging*: Records all commands entered by the attacker,
  along with input/output streams and timing data. Sessions can be saved
  as plaintext or in formats suitable for replay.

- *Fake file system and shell environment*: Emulates a basic Linux shell
  with a user-modifiable file system. Attackers can navigate directories,
  read/write fake files, or attempt to download/upload payloads.

- *Command emulation*: Supports a large set of common Unix commands (`ls`,
  `cat`, `wget`, etc.), allowing attackers to interact naturally, as
  if on a real system. And can be extended with more commands

- *Credential logging*: Captures usernames and passwords used in
  brute-force login attempts or interactive logins.

- *File download capture*: Logs and optionally stores any files attackers
  attempt to retrieve via `wget`, `curl`, or similar tools.

- *JSON-formatted logging and integration's*: Outputs structured logs that
  are easy to parse and ingest into systems like ELK, Splunk, or custom
  analysis pipelines.

Cowrie is widely used in research, threat intelligence, and proactive defense
efforts to gather Indicators of Compromise (IOCs) and understand attacker
tactics,techniques, and procedures (TTPs).

** Why Podman over Docker?
Podman offers several advantages over Docker, particularly in terms of security
and system integration. It supports rootless containers, allowing users to run
containers without elevated privileges, which reduces the attack surface.  

Podman is daemon-less, integrating more seamlessly with systemd and existing
Linux workflows. Additionally, Podman is fully compatible with the Open
Container Initiative (OCI) standards, ensuring interoperability and
flexibility across container ecosystems.

** Install cowrie as container and adjust configuration
*** üêß Create a Dedicated User for Cowrie (No Login Shell)

**1. Create the 'cowrie' user (no home directory, no login shell)**
#+begin_src sh
sudo useradd --system --no-create-home --shell /usr/sbin/nologin cowrie
#+end_src

**2. Create necessary directories and set ownership**
#+begin_src sh
sudo mkdir -p /opt/cowrie/etc
sudo mkdir -p /opt/cowrie/var
sudo chown -R cowrie:cowrie /opt/cowrie
#+end_src

*** üê≥ Pull and Configure Cowrie with Podman

**3. As the cowrie user, pull the container image**
#+begin_src bash
sudo -u cowrie podman pull cowrie/cowrie
#+end_src

**4. Copy default config file into persistent volume**
#+begin_src bash
sudo -u cowrie podman run --rm cowrie/cowrie \
  cat /cowrie/cowrie-git/etc/cowrie.cfg.dist > /opt/cowrie/etc/cowrie.cfg
#+end_src


*** üõ† cowrie.cfg ‚Äì Basic Overview

The `cowrie.cfg` file is the main configuration for **Cowrie**, the SSH/Telnet
honeypot we use. It uses INI-style syntax and is divided into sections. Each section
begins with a header like *[section_name]*.

***** üìÅ Key Sections & Settings
**[ssh] / [telnet]**
- Enable or disable SSH/Telnet and set the port to listen on::
  #+begin_src sh
  enabled = true
  listen_port = 2222
  #+end_src

**[honeypot]**
- Set honeypot host name and logpath properties:
  #+begin_src sh
    hostname = cowrie-host
 
    # Directory where to save log files in.
    log_path = var/log/cowrie
  #+end_src

- Define login behavior:
  #+begin_src sh
  auth_class = AuthRandom
  auth_class_parameters = 1, 5, 10
  #+end_src

  I use AuthRandom here which causes to allow access after "randint(2,5)"
  attempts. This means the threat actor will fail with some logins and some
  will be logged in immediately. 

**[output_jsonlog]**
- Configure logging and output plugins:
  #+begin_src sh
  [output_jsonlog]
  enabled = true
  logfile = ${honeypot:log_path}/cowrie.json
  epoch_timestamp = false
  #+end_src
  Here I set the log file path, this is important so that file beat later can
  pickup on the juicy honeypot log files.

This is the whole configuration needed to run the honeypot.

_üìå Notes_
- Restart Cowrie after configuration changes.
- You can split configuration across multiple `.cfg` files in `cowrie.cfg.d/` for modular setup.

*** üöÄ Run Cowrie Container as 'cowrie' User

**Start the Cowrie container (replace existing if needed)**
#+begin_src bash
sudo -u cowrie podman run -d --name cowrie \
  -v /opt/cowrie/etc:/cowrie/cowrie-git/etc:Z \
  -v /opt/cowrie/var:/cowrie/cowrie-git/var:Z \
  -p 2222:2222 cowrie/cowrie
#+end_src
*** üîÅ Useful Commands

- **View logs**
  #+begin_src bash
  sudo -u cowrie podman logs -f cowrie
  #+end_src

- **Restart container**
  #+begin_src bash
  sudo -u cowrie podman restart cowrie
  #+end_src

- **Stop container**
  #+begin_src bash
  sudo -u cowrie podman stop cowrie
  #+end_src

*** üîí Security Notes
- The `cowrie` user has no login shell (`/usr/sbin/no login`)
- Running Cowrie isolated via Podman increases containment
- All files are owned by `cowrie`, no root access required for normal operation

** Log Forwarding with Filebeat
*** üì¶ Install Filebeat on Ubuntu

**1. Add Elastic‚Äôs GPG key and repository**
#+begin_src bash
curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elastic.gpg

echo "deb [signed-by=/usr/share/keyrings/elastic.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | \
  sudo tee /etc/apt/sources.list.d/elastic-8.x.list
#+end_src

**2. Update APT and install Filebeat**
#+begin_src bash
sudo apt update
sudo apt install filebeat
#+end_src

*** ‚öô Configure and test Filebeat

**3. Edit Filebeat config**
#+begin_src bash
sudo mg /etc/filebeat/filebeat.yml
#+end_src
The filebeat config is straight forward. You have to write a filebeat.input
block which contains the path where the logfiles are you need to ingest. And
at the end the log-destination (logstash) so that filebeat knows where to send
the logs to: 
#+begin_src yaml
  filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /opt/cowrie/var/log/cowrie/cowrie.json
    json.keys_under_root: true
    json.add_error_key: true
    fields:
      source: cowrie
    fields_under_root: true

  output.logstash:
    hosts: ["192.168.123.5:5044"]
#+end_src

**4. (Optional) Test Filebeat config**
#+begin_src bash
sudo filebeat test config
#+end_src

*** üöÄ Start and Enable Filebeat

**5. Enable and start Filebeat**
#+begin_src bash
  sudo systemctl enable filebeat
  sudo systemctl daemon-reload
  sudo systemctl start filebeat
#+end_src

**6. Check Filebeat status and logs**
#+begin_src bash
sudo systemctl status filebeat
sudo journalctl -u filebeat -f
#+end_src

** üéØ TL;DR ‚Äì What Did We Just Do?

**1. We deployed Cowrie like pros.**
- Ran it safely in a Podman container under a non-login user.
- No mess, no root, no regrets.

**2. Logs? Sorted.**
- Filebeat scooped up Cowrie‚Äôs logs and shipped them to Elasticsearch.
- Now we can actually *see* who's knocking on the honeypot door.

**3. Everything‚Äôs persistent.**
- Configs and logs live outside the container. Cowrie forgets nothing‚Äîeven after a reboot.

**4. Setup is clean and modular.**
- Each part (Cowrie, Filebeat, Elasticsearch) does its job. 
- Break one, fix one‚Äîno domino disasters.

**5. It‚Äôs nerdy, useful, and kinda fun.**
- Now I built a mini threat intel system.
- Now I can sit back, sip coffee, and watch the kiddies play.

** Whats next
Next I had to build the HTTP honeypot, stay tuned for the follow up!

* TODO Threathunting III: HTTP Honeypot develop and setup                                 :@threathunting:honeypot:
:PROPERTIES:
:EXPORT_AUTHOR: Dirk
:EXPORT_HUGO_FRONT_MATTER_FORMAT: yaml
:HUGO_TITLE: honeyhttpd
:EXPORT_FILE_NAME: honeyhttpd
:EXPORT_DATE: 2019-01-11T16:00:00-05:00
:CUSTOM_ID: honeyhttpd
:END:
** Introduction
:PROPERTIES:
:CUSTOM_ID: introduction
:END:
*** Brief overview of the use case
:PROPERTIES:
:CUSTOM_ID: brief-overview-of-the-use-case
:END:
I recently set out to ingest web traffic data into my SIEM solution,
which requires data to be ingested in a specific format. After
researching various options, I sought an easy-to-use solution that could
integrate with our existing Elasticsearch setup. One tool that caught my
attention was HoneyPot HTTPD.

As I researched potential solutions, I realized that many of them
required manual configuration and scripting to ingest web data into
Elasticsearch. However, HoneyPot HTTPD offered a simple and elegant way
to do so through its built-in ingestion feature. This was especially
appealing since I wanted to integrate the web traffic data with our
existing SIEM setup that utilized Elasticsearch.

In particular, I needed a tool that could collect web traffic data and
forward it to a centralized location for analysis and processing.
Honeypot HTTPD's ability to ingest web data into Elasticsearch made it
an attractive choice, as it would allow me to leverage our existing
Elasticsearch infrastructure and integrate the data with our SIEM
solution seamlessly.

With this in mind, I set out to explore how to use HoneyPot HTTPD to
ingest web traffic data into Elasticsearch. In the following sections,
I'll walk you through the steps I took to configure HoneyPot HTTPD for
ingestion, including the Dockerfile used to build the container and any
additional configuration settings required.

** Setting up HoneyPot HTTPD for Web Data Ingestion
:PROPERTIES:
:CUSTOM_ID: setting-up-honeypot-httpd-for-web-data-ingestion
:END:
*** Containerizing the application to run inside docker
:PROPERTIES:
:CUSTOM_ID: containerizing-the-application-to-run-inside-docker
:END:

- Creating a Dockerfile

  I started by creating a Dockerfile that would build the HoneHTTPD
  image. The Dockerfile included the following instructions:

  #+begin_src sh
    # Use python base image
    FROM python:3

    # Set environment 
    ARG APP_NAME=honeyhttpd
    ENV APP_NAME=${APP_NAME}

    ARG USER_ID="10001"
    ARG GROUP_ID="app"
    ARG HOME="/app"

    ENV HOME=${HOME}

    # Create user and environment
    RUN groupadd --gid ${USER_ID} ${GROUP_ID} && \
        useradd --create-home --uid ${USER_ID} --gid ${GROUP_ID} --home-dir /app ${GROUP_ID}


    # Install dependencies 
    RUN apt-get update && \
        apt-get install -y --no-install-recommends \
            file        \
            gcc         \
            libwww-perl curl unzip && \
        apt-get autoremove -y && \
        apt-get clean

    # Set workdir 
    WORKDIR ${HOME}

    # Copy config files and certs into container
    COPY ./requirements.txt .
    COPY ./config.json .
    COPY ./server*.pem .
    COPY ./ca.crt . 
    COPY honeyhttpd logs servers util .
    COPY start.py .

    # Upgrade python packages and install dependencies
    RUN pip3 install --upgrade pip
    RUN pip3 install virtualenv
    RUN python3 -m virtualenv ${HOME} && \
    virtualenv ${HOME}
    RUN pip3 install --no-cache-dir --upgrade pip setuptools wheel elasticsearch && \
    pip3 install --no-cache-dir --upgrade -r ./requirements.txt && pip3 install -r ./requirements.txt

    ADD . ${HOME}

    # Remove compilers
    RUN apt-get remove gcc --purge -y

        # Drop root and change ownership of the application folder to the user
    RUN chown -R ${USER_ID}:${GROUP_ID} ${HOME}
    USER ${USER_ID}

    # Expose Honeypot ports to outside world
    EXPOSE 8888:8888
    EXPOSE 8889:8889
    EXPOSE 8443:8443

    # run cowrie with config
    CMD ["python3", "start.py", "--config", "config.json"]
  #+end_src

  In this Dockerfile, I:

  - Used the official Ubuntu image as the base image
  - Installed necessary dependencies, including Python and pip
  - Installed the required packages, including HoneyPot HTTPD
  - Set the working directory to /usr/local/bin to run the application
    from
  - Exposed port 80 for HTTP traffic
  - Copied the configuration file (config.yaml) into the container
  - Specified the command to run HoneyPot HTTPD with the -c option,
    which points
  - to the configuration file

- Building and Running the Container

  Once I had created the Dockerfile, I built the image by running the
  following command:

  #+begin_src sh
  docker build -t honeyhttpd .
  #+end_src

  This command told Docker to create an image with the tag honeyhttpd
  using the instructions in the Dockerfile.To run the container, I used
  the following command:

  #+begin_src sh
  docker run -p 80:80 honeyhttpd
  #+end_src

  This command started a new container from the honeyhttpd image and
  mapped port 80 on the host machine to port 80 in the container.

- Configuring the Container

  To configure the container, I updated the config.yaml file to point to
  my Elasticsearch instance. Here's an example of what the configuration
  file might look like:

  #+begin_src sh
  -ingest:
  es_host: "localhost:9200"
  es_index: "logstash-2019.04"
  es_type: "log"
  #+end_src

  This configuration told HoneyPot HTTPD to forward web traffic data to
  my Elasticsearch instance, where it could be processed and stored.

  With the container running and configured, I was now ready to test
  HoneyPot HTTPD's ability to ingest web traffic data into
  Elasticsearch.

** Ingesting Web Data into Elasticsearch with HoneyPot HTTPD
:PROPERTIES:
:CUSTOM_ID: iii-dot-ingesting-web-data-into-elasticsearch-with-honeypot-httpd
:END:
*** Explanation of how to use the honeyhttpd command-line tool to ingest web data into Elasticsearch
:PROPERTIES:
:CUSTOM_ID: explanation-of-how-to-use-the-honeyhttpd-command-line-tool-to-ingest-web-data-into-elasticsearch
:END:
*** Example of how to configure the honeyhttpd output to match your desired Elasticsearch index structure
:PROPERTIES:
:CUSTOM_ID: example-of-how-to-configure-the-honeyhttpd-output-to-match-your-desired-elasticsearch-index-structure
:END:
** Benefits and Use Cases
:PROPERTIES:
:CUSTOM_ID: iv-dot-benefits-and-use-cases
:END:
*** Discussion of the benefits of using HoneyPot HTTPD for ingesting web data into Elasticsearch (e.g., improved threat detection, enhanced visibility)
:PROPERTIES:
:CUSTOM_ID: discussion-of-the-benefits-of-using-honeypot-httpd-for-ingesting-web-data-into-elasticsearch--e-dot-g-dot-improved-threat-detection-enhanced-visibility
:END:
*** Real-world examples of use cases where this setup can be particularly effective (e.g., logging web traffic, monitoring online activity)
:PROPERTIES:
:CUSTOM_ID: real-world-examples-of-use-cases-where-this-setup-can-be-particularly-effective--e-dot-g-dot-logging-web-traffic-monitoring-online-activity
:END:
** Conclusion
:PROPERTIES:
:CUSTOM_ID: v-dot-conclusion
:END:
*** Recap of key points about using HoneyPot HTTPD to ingest web data into Elasticsearch
:PROPERTIES:
:CUSTOM_ID: recap-of-key-points-about-using-honeypot-httpd-to-ingest-web-data-into-elasticsearch
:END:
*** Final thoughts on the value of this setup for your organization's threat hunting or security operations.
:PROPERTIES:
:CUSTOM_ID: final-thoughts-on-the-value-of-this-setup-for-your-organization-s-threat-hunting-or-security-operations-dot
:END:
* DRAFT Threathunting IV: Setup ELK Server and ingest data                                :@threathunting:visibility:
