<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.142.0">
    <meta name="generator" content="Relearn 8.0.0+9803d5122ebb3276acea823f476e9eb44f607862">
    <meta name="description" content="Introduction Brief overview of the use case Setting up HoneyPot HTTPD for Web Data Ingestion and adjust code for our needs Containerizing the application to run inside docker Code adjustments for our environment Ingesting Web Data into Elasticsearch with HoneyPot HTTPD Explanation of how to use the honeyhttpd command-line tool to ingest web data into Elasticsearch Example of how to configure the honeyhttpd output to match your desired Elasticsearch index structure Benefits and Use Cases Discussion of the benefits of using HoneyPot HTTPD for ingesting web data into Elasticsearch (e.g., improved threat detection, enhanced visibility) Real-world examples of use cases where this setup can be particularly effective (e.g., logging web traffic, monitoring online activity) Conclusion Recap of key points about using HoneyPot HTTPD to ingest web data into Elasticsearch Final thoughts on the value of this setup for your organization‚Äôs threat hunting or security operations. Introduction Brief overview of the use case I recently set out to ingest web traffic data into my SIEM solution, which requires data to be ingested in a specific format. After researching various options, I sought an easy-to-use solution that could integrate with our existing Elasticsearch setup. One tool that caught my attention was HoneyPot HTTPD.">
    <meta name="author" content="Dirk">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Threathunting III: HTTP Honeypot develop and setup - Forensic wheels">
    <meta name="twitter:description" content="Introduction Brief overview of the use case Setting up HoneyPot HTTPD for Web Data Ingestion and adjust code for our needs Containerizing the application to run inside docker Code adjustments for our environment Ingesting Web Data into Elasticsearch with HoneyPot HTTPD Explanation of how to use the honeyhttpd command-line tool to ingest web data into Elasticsearch Example of how to configure the honeyhttpd output to match your desired Elasticsearch index structure Benefits and Use Cases Discussion of the benefits of using HoneyPot HTTPD for ingesting web data into Elasticsearch (e.g., improved threat detection, enhanced visibility) Real-world examples of use cases where this setup can be particularly effective (e.g., logging web traffic, monitoring online activity) Conclusion Recap of key points about using HoneyPot HTTPD to ingest web data into Elasticsearch Final thoughts on the value of this setup for your organization‚Äôs threat hunting or security operations. Introduction Brief overview of the use case I recently set out to ingest web traffic data into my SIEM solution, which requires data to be ingested in a specific format. After researching various options, I sought an easy-to-use solution that could integrate with our existing Elasticsearch setup. One tool that caught my attention was HoneyPot HTTPD.">
    <meta property="og:url" content="http://localhost:1313/posts/honeyhttpd/index.html">
    <meta property="og:site_name" content="Forensic wheels">
    <meta property="og:title" content="Threathunting III: HTTP Honeypot develop and setup - Forensic wheels">
    <meta property="og:description" content="Introduction Brief overview of the use case Setting up HoneyPot HTTPD for Web Data Ingestion and adjust code for our needs Containerizing the application to run inside docker Code adjustments for our environment Ingesting Web Data into Elasticsearch with HoneyPot HTTPD Explanation of how to use the honeyhttpd command-line tool to ingest web data into Elasticsearch Example of how to configure the honeyhttpd output to match your desired Elasticsearch index structure Benefits and Use Cases Discussion of the benefits of using HoneyPot HTTPD for ingesting web data into Elasticsearch (e.g., improved threat detection, enhanced visibility) Real-world examples of use cases where this setup can be particularly effective (e.g., logging web traffic, monitoring online activity) Conclusion Recap of key points about using HoneyPot HTTPD to ingest web data into Elasticsearch Final thoughts on the value of this setup for your organization‚Äôs threat hunting or security operations. Introduction Brief overview of the use case I recently set out to ingest web traffic data into my SIEM solution, which requires data to be ingested in a specific format. After researching various options, I sought an easy-to-use solution that could integrate with our existing Elasticsearch setup. One tool that caught my attention was HoneyPot HTTPD.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="Forensic wheels">
    <meta property="article:published_time" content="2019-01-11T16:00:00-05:00">
    <meta property="article:modified_time" content="2025-08-01T18:02:01+02:00">
    <meta property="article:tag" content="Threathunting">
    <meta property="article:tag" content="Honeypot">
    <meta itemprop="name" content="Threathunting III: HTTP Honeypot develop and setup - Forensic wheels">
    <meta itemprop="description" content="Introduction Brief overview of the use case Setting up HoneyPot HTTPD for Web Data Ingestion and adjust code for our needs Containerizing the application to run inside docker Code adjustments for our environment Ingesting Web Data into Elasticsearch with HoneyPot HTTPD Explanation of how to use the honeyhttpd command-line tool to ingest web data into Elasticsearch Example of how to configure the honeyhttpd output to match your desired Elasticsearch index structure Benefits and Use Cases Discussion of the benefits of using HoneyPot HTTPD for ingesting web data into Elasticsearch (e.g., improved threat detection, enhanced visibility) Real-world examples of use cases where this setup can be particularly effective (e.g., logging web traffic, monitoring online activity) Conclusion Recap of key points about using HoneyPot HTTPD to ingest web data into Elasticsearch Final thoughts on the value of this setup for your organization‚Äôs threat hunting or security operations. Introduction Brief overview of the use case I recently set out to ingest web traffic data into my SIEM solution, which requires data to be ingested in a specific format. After researching various options, I sought an easy-to-use solution that could integrate with our existing Elasticsearch setup. One tool that caught my attention was HoneyPot HTTPD.">
    <meta itemprop="datePublished" content="2019-01-11T16:00:00-05:00">
    <meta itemprop="dateModified" content="2025-08-01T18:02:01+02:00">
    <meta itemprop="wordCount" content="1580">
    <meta itemprop="keywords" content="Threathunting,Honeypot">
    <title>Threathunting III: HTTP Honeypot develop and setup - Forensic wheels</title>
    <link href="/images/logo.svg?1754342926" rel="icon" type="image/svg+xml">
    <link href="/css/auto-complete/auto-complete.min.css?1754342926" rel="stylesheet">
    <script src="/js/auto-complete/auto-complete.min.js?1754342926" defer></script>
    <script src="/js/search-lunr.js?1754342926" defer></script>
    <script src="/js/search.js?1754342926" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/searchindex.en.js?1754342926";
    </script>
    <script src="/js/lunr/lunr.min.js?1754342926" defer></script>
    <script src="/js/lunr/lunr.stemmer.support.min.js?1754342926" defer></script>
    <script src="/js/lunr/lunr.multi.min.js?1754342926" defer></script>
    <script src="/js/lunr/lunr.en.min.js?1754342926" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="/fonts/fontawesome/css/fontawesome-all.min.css?1754342926" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/fonts/fontawesome/css/fontawesome-all.min.css?1754342926" rel="stylesheet"></noscript>
    <link href="/css/perfect-scrollbar/perfect-scrollbar.min.css?1754342926" rel="stylesheet">
    <link href="/css/theme.css?1754342926" rel="stylesheet">
    <link href="/css/format-html.css?1754342926" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/posts\/honeyhttpd\/index.html';
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto', 'neon' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
  </head>
  <body class="mobile-support html" data-url="/posts/honeyhttpd/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a>
      <ul>
        <li><a href="#brief-overview-of-the-use-case">Brief overview of the use case</a></li>
      </ul>
    </li>
    <li><a href="#setting-up-honeypot-httpd-for-web-data-ingestion">Setting up HoneyPot HTTPD for Web Data Ingestion and adjust code for our needs</a>
      <ul>
        <li><a href="#containerizing-the-application-to-run-inside-docker">Containerizing the application to run inside docker</a></li>
        <li><a href="#code-adjustments-for-our-environment">Code adjustments for our environment</a></li>
      </ul>
    </li>
    <li><a href="#iii-dot-ingesting-web-data-into-elasticsearch-with-honeypot-httpd">Ingesting Web Data into Elasticsearch with HoneyPot HTTPD</a>
      <ul>
        <li><a href="#explanation-of-how-to-use-the-honeyhttpd-command-line-tool-to-ingest-web-data-into-elasticsearch">Explanation of how to use the honeyhttpd command-line tool to ingest web data into Elasticsearch</a></li>
        <li><a href="#example-of-how-to-configure-the-honeyhttpd-output-to-match-your-desired-elasticsearch-index-structure">Example of how to configure the honeyhttpd output to match your desired Elasticsearch index structure</a></li>
      </ul>
    </li>
    <li><a href="#iv-dot-benefits-and-use-cases">Benefits and Use Cases</a>
      <ul>
        <li><a href="#discussion-of-the-benefits-of-using-honeypot-httpd-for-ingesting-web-data-into-elasticsearch--e-dot-g-dot-improved-threat-detection-enhanced-visibility">Discussion of the benefits of using HoneyPot HTTPD for ingesting web data into Elasticsearch (e.g., improved threat detection, enhanced visibility)</a></li>
        <li><a href="#real-world-examples-of-use-cases-where-this-setup-can-be-particularly-effective--e-dot-g-dot-logging-web-traffic-monitoring-online-activity">Real-world examples of use cases where this setup can be particularly effective (e.g., logging web traffic, monitoring online activity)</a></li>
      </ul>
    </li>
    <li><a href="#v-dot-conclusion">Conclusion</a>
      <ul>
        <li><a href="#recap-of-key-points-about-using-honeypot-httpd-to-ingest-web-data-into-elasticsearch">Recap of key points about using HoneyPot HTTPD to ingest web data into Elasticsearch</a></li>
        <li><a href="#final-thoughts-on-the-value-of-this-setup-for-your-organization-s-threat-hunting-or-security-operations-dot">Final thoughts on the value of this setup for your organization&rsquo;s threat hunting or security operations.</a></li>
      </ul>
    </li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <span class="topbar-breadcrumbs highlightable">
            Threathunting III: HTTP Honeypot develop and setup
          </span>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable posts" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
<div class="R-taxonomy taxonomy-tags cstyle tags" title="Tags" style="--VARIABLE-TAGS-BG-color: var(--INTERNAL-TAG-BG-color);">
  <ul>
    <li><a class="term-link" href="/tags/honeypot/index.html">Honeypot</a></li>
    <li><a class="term-link" href="/tags/threathunting/index.html">Threathunting</a></li>
  </ul>
</div>
  </header>

<h1 id="threathunting-iii-http-honeypot-develop-and-setup">Threathunting III: HTTP Honeypot develop and setup</h1>

<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<ul>
<li><a href="/posts/honeyhttpd/index.html#introduction">Introduction</a>
<ul>
<li><a href="/posts/honeyhttpd/index.html#brief-overview-of-the-use-case">Brief overview of the use case</a></li>
</ul>
</li>
<li><a href="/posts/honeyhttpd/index.html#setting-up-honeypot-httpd-for-web-data-ingestion">Setting up HoneyPot HTTPD for Web Data Ingestion and adjust code for our needs</a>
<ul>
<li><a href="/posts/honeyhttpd/index.html#containerizing-the-application-to-run-inside-docker">Containerizing the application to run inside docker</a></li>
<li><a href="/posts/honeyhttpd/index.html#code-adjustments-for-our-environment">Code adjustments for our environment</a></li>
</ul>
</li>
<li><a href="/posts/honeyhttpd/index.html#iii-dot-ingesting-web-data-into-elasticsearch-with-honeypot-httpd">Ingesting Web Data into Elasticsearch with HoneyPot HTTPD</a>
<ul>
<li><a href="/posts/honeyhttpd/index.html#explanation-of-how-to-use-the-honeyhttpd-command-line-tool-to-ingest-web-data-into-elasticsearch">Explanation of how to use the honeyhttpd command-line tool to ingest web data into Elasticsearch</a></li>
<li><a href="/posts/honeyhttpd/index.html#example-of-how-to-configure-the-honeyhttpd-output-to-match-your-desired-elasticsearch-index-structure">Example of how to configure the honeyhttpd output to match your desired Elasticsearch index structure</a></li>
</ul>
</li>
<li><a href="/posts/honeyhttpd/index.html#iv-dot-benefits-and-use-cases">Benefits and Use Cases</a>
<ul>
<li><a href="/posts/honeyhttpd/index.html#discussion-of-the-benefits-of-using-honeypot-httpd-for-ingesting-web-data-into-elasticsearch--e-dot-g-dot-improved-threat-detection-enhanced-visibility">Discussion of the benefits of using HoneyPot HTTPD for ingesting web data into Elasticsearch (e.g., improved threat detection, enhanced visibility)</a></li>
<li><a href="/posts/honeyhttpd/index.html#real-world-examples-of-use-cases-where-this-setup-can-be-particularly-effective--e-dot-g-dot-logging-web-traffic-monitoring-online-activity">Real-world examples of use cases where this setup can be particularly effective (e.g., logging web traffic, monitoring online activity)</a></li>
</ul>
</li>
<li><a href="/posts/honeyhttpd/index.html#v-dot-conclusion">Conclusion</a>
<ul>
<li><a href="/posts/honeyhttpd/index.html#recap-of-key-points-about-using-honeypot-httpd-to-ingest-web-data-into-elasticsearch">Recap of key points about using HoneyPot HTTPD to ingest web data into Elasticsearch</a></li>
<li><a href="/posts/honeyhttpd/index.html#final-thoughts-on-the-value-of-this-setup-for-your-organization-s-threat-hunting-or-security-operations-dot">Final thoughts on the value of this setup for your organization&rsquo;s threat hunting or security operations.</a></li>
</ul>
</li>
</ul>
<!-- raw HTML omitted -->
<h2 id="introduction">Introduction</h2>
<h3 id="brief-overview-of-the-use-case">Brief overview of the use case</h3>
<p>I recently set out to ingest web traffic data into my SIEM solution,
which requires data to be ingested in a specific format. After
researching various options, I sought an easy-to-use solution that could
integrate with our existing Elasticsearch setup. One tool that caught my
attention was HoneyPot HTTPD.</p>
<p>As I researched potential solutions, I realized that many of them
required manual configuration and scripting to ingest web data into
Elasticsearch. However, HoneyPot HTTPD offered a simple and elegant way
to do so through its built-in ingestion feature. This was especially
appealing since I wanted to integrate the web traffic data with our
existing SIEM setup that utilized Elasticsearch.</p>
<p>In particular, I needed a tool that could collect web traffic data and
forward it to a centralized location for analysis and processing.
Honeypot HTTPD&rsquo;s ability to ingest web data into Elasticsearch made it
an attractive choice, as it would allow me to leverage our existing
Elasticsearch infrastructure and integrate the data with our SIEM
solution seamlessly.</p>
<p>With this in mind, I set out to explore how to use HoneyPot HTTPD to
ingest web traffic data into Elasticsearch. In the following sections,
I&rsquo;ll walk you through the steps I took to configure HoneyPot HTTPD for
ingestion, including the Dockerfile used to build the container and any
additional configuration settings required.</p>
<h2 id="setting-up-honeypot-httpd-for-web-data-ingestion">Setting up HoneyPot HTTPD for Web Data Ingestion and adjust code for our needs</h2>
<h3 id="containerizing-the-application-to-run-inside-docker">Containerizing the application to run inside docker</h3>
<ul>
<li>
<p>Creating a Dockerfile</p>
<p>I started by creating a Dockerfile that would build the HoneHTTPD
image. The Dockerfile included the following instructions:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># Use python base image</span>
</span></span><span style="display:flex;"><span>FROM python:3
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Set environment</span>
</span></span><span style="display:flex;"><span>ARG APP_NAME<span style="color:#f92672">=</span>honeyhttpd
</span></span><span style="display:flex;"><span>ENV APP_NAME<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>APP_NAME<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ARG USER_ID<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;10001&#34;</span>
</span></span><span style="display:flex;"><span>ARG GROUP_ID<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;app&#34;</span>
</span></span><span style="display:flex;"><span>ARG HOME<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;/app&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ENV HOME<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>HOME<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create user and environment</span>
</span></span><span style="display:flex;"><span>RUN groupadd --gid <span style="color:#e6db74">${</span>USER_ID<span style="color:#e6db74">}</span> <span style="color:#e6db74">${</span>GROUP_ID<span style="color:#e6db74">}</span> <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    useradd --create-home --uid <span style="color:#e6db74">${</span>USER_ID<span style="color:#e6db74">}</span> --gid <span style="color:#e6db74">${</span>GROUP_ID<span style="color:#e6db74">}</span> --home-dir /app <span style="color:#e6db74">${</span>GROUP_ID<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Install dependencies</span>
</span></span><span style="display:flex;"><span>RUN apt-get update <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    apt-get install -y --no-install-recommends <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        file        <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        gcc         <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        libwww-perl curl unzip <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    apt-get autoremove -y <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    apt-get clean
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Set workdir</span>
</span></span><span style="display:flex;"><span>WORKDIR <span style="color:#e6db74">${</span>HOME<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Copy config files and certs into container</span>
</span></span><span style="display:flex;"><span>COPY ./requirements.txt .
</span></span><span style="display:flex;"><span>COPY ./config.json .
</span></span><span style="display:flex;"><span>COPY ./server*.pem .
</span></span><span style="display:flex;"><span>COPY ./ca.crt .
</span></span><span style="display:flex;"><span>COPY honeyhttpd logs servers util .
</span></span><span style="display:flex;"><span>COPY start.py .
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Upgrade python packages and install dependencies</span>
</span></span><span style="display:flex;"><span>RUN pip3 install --upgrade pip
</span></span><span style="display:flex;"><span>RUN pip3 install virtualenv
</span></span><span style="display:flex;"><span>RUN python3 -m virtualenv <span style="color:#e6db74">${</span>HOME<span style="color:#e6db74">}</span> <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>virtualenv <span style="color:#e6db74">${</span>HOME<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>RUN pip3 install --no-cache-dir --upgrade pip setuptools wheel elasticsearch <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>pip3 install --no-cache-dir --upgrade -r ./requirements.txt <span style="color:#f92672">&amp;&amp;</span> pip3 install -r ./requirements.txt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ADD . <span style="color:#e6db74">${</span>HOME<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Remove compilers</span>
</span></span><span style="display:flex;"><span>RUN apt-get remove gcc --purge -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Drop root and change ownership of the application folder to the user</span>
</span></span><span style="display:flex;"><span>RUN chown -R <span style="color:#e6db74">${</span>USER_ID<span style="color:#e6db74">}</span>:<span style="color:#e6db74">${</span>GROUP_ID<span style="color:#e6db74">}</span> <span style="color:#e6db74">${</span>HOME<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>USER <span style="color:#e6db74">${</span>USER_ID<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Expose Honeypot ports to outside world</span>
</span></span><span style="display:flex;"><span>EXPOSE 8888:8888
</span></span><span style="display:flex;"><span>EXPOSE 8889:8889
</span></span><span style="display:flex;"><span>EXPOSE 8443:8443
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># run cowrie with config</span>
</span></span><span style="display:flex;"><span>CMD <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;python3&#34;</span>, <span style="color:#e6db74">&#34;start.py&#34;</span>, <span style="color:#e6db74">&#34;--config&#34;</span>, <span style="color:#e6db74">&#34;config.json&#34;</span><span style="color:#f92672">]</span></span></span></code></pre></div>
<p>In this Dockerfile, I:</p>
<ul>
<li>Used the official Ubuntu image as the base image</li>
<li>Installed necessary dependencies, including Python and pip</li>
<li>Installed the required packages, including HoneyPot HTTPD</li>
<li>Set the working directory to /usr/local/bin to run the application
from</li>
<li>Exposed port 80 for HTTP traffic</li>
<li>Copied the configuration file (config.yaml) into the container</li>
<li>Specified the command to run HoneyPot HTTPD with the -c option,
which points</li>
<li>to the configuration file</li>
</ul>
</li>
<li>
<p>Building and Running the Container</p>
<p>Once I had created the Dockerfile, I built the image by running the
following command:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>docker build -t honeyhttpd .</span></span></code></pre></div>
<p>This command told Docker to create an image with the tag honeyhttpd
using the instructions in the Dockerfile.To run the container, I used
the following command:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>docker run -p 80:80 honeyhttpd</span></span></code></pre></div>
<p>This command started a new container from the honeyhttpd image and
mapped port 80 on the host machine to port 80 in the container.</p>
</li>
<li>
<p>Configuring the Container</p>
<p>To configure the container, I updated the config.yaml file to point to
my Elasticsearch instance. Here&rsquo;s an example of what the configuration
file might look like:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>-ingest:
</span></span><span style="display:flex;"><span>es_host: <span style="color:#e6db74">&#34;localhost:9200&#34;</span>
</span></span><span style="display:flex;"><span>es_index: <span style="color:#e6db74">&#34;logstash-2019.04&#34;</span>
</span></span><span style="display:flex;"><span>es_type: <span style="color:#e6db74">&#34;log&#34;</span></span></span></code></pre></div>
<p>This configuration told HoneyPot HTTPD to forward web traffic data to
my Elasticsearch instance, where it could be processed and stored.</p>
<p>With the container running and configured, I was now ready to test
HoneyPot HTTPD&rsquo;s ability to ingest web traffic data into
Elasticsearch.</p>
</li>
</ul>
<h3 id="code-adjustments-for-our-environment">Code adjustments for our environment</h3>
<h4 id="major-improvements-in-apachepasswordserver-dot-py-credential-capture-logging-and-header-parsing">üîê Major Improvements in `ApachePasswordServer.py`: Credential Capture, Logging, and Header Parsing</h4>
<p>This update significantly enhances `ApachePasswordServer.py` by simulating Basic Authentication, extracting credentials from the `Authorization` header, and enriching log data with structured request and response metadata. It also ensures integration with `ElasticSearchLogger` and introduces helper functions for safer parsing and decoding.</p>
<ul>
<li>
<p>üìä Summary of Changes</p>
<ul>
<li>1 file changed: `ApachePasswordServer.py`</li>
<li>~120 insertions, ~10 deletions</li>
<li>Key improvements:
<ul>
<li>Basic Auth simulation (401 challenge)</li>
<li>Credential harvesting from Authorization header</li>
<li>Integration with `ElasticSearchLogger`</li>
<li>Structured logging with metadata (IP, method, headers)</li>
</ul>
</li>
</ul>
<hr>
</li>
</ul>
<ul>
<li>
<p>üÜï Auto-Injection of `ElasticSearchLogger` in `_<em>init</em>_()`</p>
<p>To ensure consistent structured logging, `ElasticSearchLogger` is now injected into the logger stack if not already present.</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-diff" data-lang="diff"><span style="display:flex;"><span><span style="color:#a6e22e">+ if loggers is None:
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+     loggers = []
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+ if not any(isinstance(logger, ElasticSearchLogger) for logger in loggers):
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+     loggers.append(ElasticSearchLogger())
</span></span></span></code></pre></div>
<p>This avoids missing logs if the user forgets to pass a logger during instantiation.</p>
<hr>
</li>
</ul>
<ul>
<li>
<p>üîê New GET Handler Simulates Apache Basic Auth Challenge</p>
<p>The server now returns `401 Unauthorized` and prompts for credentials on common admin paths.</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-diff" data-lang="diff"><span style="display:flex;"><span><span style="color:#a6e22e">+ def on_GET(self, path, headers):
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+     if path in [&#34;/&#34;, &#34;/index.php&#34;, &#34;/admin&#34;]:
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+         return 401, [], &#39;Basic realm=&#34;Secure Area&#34;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+     return 404, [], &#34;&#34;
</span></span></span></code></pre></div>
<p>This turns the honeypot into a credential trap for automated brute-forcers and scanners.</p>
<hr>
</li>
</ul>
<ul>
<li>
<p>üß∞ New Helper Functions for Header Parsing and Auth Decoding</p>
<p>Two utility functions were introduced:</p>
<ul>
<li>`parse_to_json()` transforms header tuples into a JSON dictionary.</li>
<li>`decode_basic_auth()` decodes Base64 credentials and validates them.</li>
</ul>
<!-- raw HTML omitted -->
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">parse_to_json</span>(data):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> json<span style="color:#f92672">.</span>dumps({key: value <span style="color:#66d9ef">for</span> key, value <span style="color:#f92672">in</span> data})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">decode_basic_auth</span>(b64_string):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        decoded_bytes <span style="color:#f92672">=</span> base64<span style="color:#f92672">.</span>b64decode(b64_string, validate<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        decoded_str <span style="color:#f92672">=</span> decoded_bytes<span style="color:#f92672">.</span>decode(<span style="color:#e6db74">&#39;utf-8&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#e6db74">&#39;:&#39;</span> <span style="color:#f92672">in</span> decoded_str:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> decoded_str
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34;[invalid format: missing colon]&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;[decode error: </span><span style="color:#e6db74">{</span>e<span style="color:#e6db74">}</span><span style="color:#e6db74">]&#34;</span></span></span></code></pre></div>
<p>These enable safe and consistent parsing for incoming HTTP headers.</p>
<hr>
</li>
</ul>
<ul>
<li>
<p>üì¶ Structured Request Parsing &amp; Credential Extraction in `on_complete()`</p>
<p>The `on_complete()` method has been completely reworked to:</p>
<ul>
<li>Parse the HTTP request line</li>
<li>Convert headers to a JSON object</li>
<li>Extract relevant metadata and credentials</li>
<li>Store all data in `req_dict`, passed to the logger</li>
</ul>
<!-- raw HTML omitted -->
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-diff" data-lang="diff"><span style="display:flex;"><span><span style="color:#f92672">-        extra = {}
</span></span></span><span style="display:flex;"><span><span style="color:#f92672"></span><span style="color:#a6e22e">+        req_dict = {}
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e"></span>...
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        lines = request.split(&#39;\n&#39;)
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        first_line = lines[0].strip()
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        parts = first_line.split()
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        requested_url = parts[1] if len(parts) &gt; 1 else &#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        method = parts[0] if len(parts) &gt; 0 else &#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        req_dict[&#39;request_body&#39;] = requested_url
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        req_dict[&#39;method&#39;] = method
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        req_dict[&#39;code&#39;] = code
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        try:
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+            req_output = parse_to_json(req_headers)
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+            parsed_req = json.loads(req_output)
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        except Exception as e:
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+            parsed_req = {}
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        for key in [&#39;Host&#39;, &#39;User-Agent&#39;, &#39;Accept&#39;, &#39;Accept-Language&#39;,
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+                    &#39;Accept-Encoding&#39;, &#39;Authorization&#39;]:
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+            req_dict[key] = parsed_req.get(key, &#39;&#39;)
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        auth = parsed_req.get(&#39;Authorization&#39;, &#39;&#39;)
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        if auth.startswith(&#34;Basic &#34;):
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+            try:
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+                auth_data = auth.split(&#34; &#34;, 1)[1]
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+                decoded_creds = encode.decode_base64(auth_data)
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+                req_dict[&#39;creds&#39;] = decoded_creds
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+            except Exception as e:
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+                req_dict[&#39;creds&#39;] = f&#34;[decode error: {e}]&#34;
</span></span></span></code></pre></div>
<p>This prepares your logs to include useful hunting metadata for later analysis.</p>
<hr>
</li>
</ul>
<ul>
<li>
<p>üåê Enriched Connection Metadata Logging</p>
<p>Additional context is logged to `req_dict`, including:</p>
<ul>
<li>Remote IP and port</li>
<li>SSL usage</li>
<li>Listening port</li>
<li>HTTP response code</li>
<li>Response headers</li>
</ul>
<!-- raw HTML omitted -->
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-diff" data-lang="diff"><span style="display:flex;"><span><span style="color:#a6e22e">+        remote_ip = client[0] if isinstance(client, tuple) else &#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        remote_port = client[1] if isinstance(client, tuple) else &#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        is_ssl = getattr(self, &#39;is_ssl&#39;, False)
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        port = getattr(self, &#39;port&#39;, &#39;8843&#39;)
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        req_dict[&#39;remote_ip&#39;] = remote_ip
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        req_dict[&#39;remote_port&#39;] = remote_port
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        req_dict[&#39;is_ssl&#39;] = is_ssl
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        req_dict[&#39;port&#39;] = port
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        req_dict[&#39;response_headers&#39;] = res_dict
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+        self.log(client, request, response, res_dict, req_dict)
</span></span></span></code></pre></div>
<p>This provides rich forensic data for Elasticsearch or Splunk pipelines.</p>
<hr>
</li>
</ul>
<ul>
<li>
<p>‚úÖ Result</p>
<p>These changes turn `ApachePasswordServer` into a more useful honeypot component for DFIR or threat hunting research.</p>
<p>It now supports:</p>
<ul>
<li>Credential collection from Basic Auth attacks</li>
<li>Well-structured logs for easy ingestion</li>
<li>Full IP/session/request context per event</li>
<li>Easier extensibility for new headers or paths</li>
</ul>
<p>You‚Äôre now well-positioned to integrate this into a broader threat hunting or research stack.</p>
</li>
</ul>
<h2 id="iii-dot-ingesting-web-data-into-elasticsearch-with-honeypot-httpd">Ingesting Web Data into Elasticsearch with HoneyPot HTTPD</h2>
<h3 id="explanation-of-how-to-use-the-honeyhttpd-command-line-tool-to-ingest-web-data-into-elasticsearch">Explanation of how to use the honeyhttpd command-line tool to ingest web data into Elasticsearch</h3>
<h3 id="example-of-how-to-configure-the-honeyhttpd-output-to-match-your-desired-elasticsearch-index-structure">Example of how to configure the honeyhttpd output to match your desired Elasticsearch index structure</h3>
<h2 id="iv-dot-benefits-and-use-cases">Benefits and Use Cases</h2>
<h3 id="discussion-of-the-benefits-of-using-honeypot-httpd-for-ingesting-web-data-into-elasticsearch--e-dot-g-dot-improved-threat-detection-enhanced-visibility">Discussion of the benefits of using HoneyPot HTTPD for ingesting web data into Elasticsearch (e.g., improved threat detection, enhanced visibility)</h3>
<h3 id="real-world-examples-of-use-cases-where-this-setup-can-be-particularly-effective--e-dot-g-dot-logging-web-traffic-monitoring-online-activity">Real-world examples of use cases where this setup can be particularly effective (e.g., logging web traffic, monitoring online activity)</h3>
<h2 id="v-dot-conclusion">Conclusion</h2>
<h3 id="recap-of-key-points-about-using-honeypot-httpd-to-ingest-web-data-into-elasticsearch">Recap of key points about using HoneyPot HTTPD to ingest web data into Elasticsearch</h3>
<h3 id="final-thoughts-on-the-value-of-this-setup-for-your-organization-s-threat-hunting-or-security-operations-dot">Final thoughts on the value of this setup for your organization&rsquo;s threat hunting or security operations.</h3>

  <footer class="footline">
              <i class='fa-fw fas fa-calendar'></i> Jan 11, 2019
<div class="R-taxonomy taxonomy-categories cstyle" title="Categories" style="--VARIABLE-TAGS-BG-color: var(--INTERNAL-TAG-BG-color);">
  <i class="fa-fw fas fa-layer-group"></i>
  <ul>
    <li><a class="term-link" href="/categories/threathunting/index.html">Threathunting</a></li>
  </ul>
</div>
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/index.html">
            <div class="logo-title">Forensic wheels</div>
          </a>
        </div>
        <search><form action="/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="parent " data-nav-id="/posts/index.html"><a class="padding" href="/posts/index.html">Forensic wheels</a><ul id="R-subsections-b4e55eb7e39db1aee6d02808a2267090" class="collapsible-menu">
            <li class="" data-nav-id="/posts/threathuntingnet/index.html"><a class="padding" href="/posts/threathuntingnet/index.html">Threathunting I: Network setup</a></li>
            <li class="" data-nav-id="/posts/theathuntinghoneypot/index.html"><a class="padding" href="/posts/theathuntinghoneypot/index.html">Threat hunting II: SSH Honeypot setup</a></li>
            <li class="active " data-nav-id="/posts/honeyhttpd/index.html"><a class="padding" href="/posts/honeyhttpd/index.html">Threathunting III: HTTP Honeypot develop and setup</a></li>
            <li class="" data-nav-id="/posts/sans_for608/index.html"><a class="padding" href="/posts/sans_for608/index.html">SANS FOR608</a></li>
            <li class="" data-nav-id="/posts/openbsdzen/index.html"><a class="padding" href="/posts/openbsdzen/index.html">OpenBSD and Zen</a></li></ul></li>
            <li class="" data-nav-id="/about/index.html"><a class="padding" href="/about/index.html">About</a></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
            <li class="R-variantswitcher">
              <div class="padding menu-control">
                <i class="fa-fw fas fa-paint-brush"></i>
                <span>&nbsp;</span>
                <div class="control-style">
                  <label class="a11y-only" for="R-select-variant">Theme</label>
                  <select id="R-select-variant">
                    <option id="R-select-variant-auto" value="auto" selected>Auto</option>
                    <option id="R-select-variant-neon" value="neon">Neon</option>
                  </select>
                </div>
                <div class="clear"></div>
              </div>
              <script>window.relearn.markVariant();</script>
            </li>
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script src="/js/clipboard/clipboard.min.js?1754342926" defer></script>
    <script src="/js/perfect-scrollbar/perfect-scrollbar.min.js?1754342926" defer></script>
    <script src="/js/theme.js?1754342926" defer></script>
  </body>
</html>
